2025-01-21 16:11:54,362 - cli.py - This is Paynt version 0.1.0.
2025-01-21 16:11:54,362 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/omdt/frozenlake_8x8/model-random.drn ...
2025-01-21 16:11:54,362 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 16:11:54,363 - sketch.py - assuming sketch in DRN format...
2025-01-21 16:11:54,364 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/omdt/frozenlake_8x8/discounted.props ...
2025-01-21 16:11:54,364 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 16:11:54,364 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/omdt/frozenlake_8x8/state-valuations.json, adding to the model...
2025-01-21 16:11:54,364 - sketch.py - sketch parsing OK
2025-01-21 16:11:54,365 - sketch.py - constructed explicit quotient having 64 states and 320 choices
2025-01-21 16:11:54,365 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 16:11:54,365 - mdp.py - MDP has 53/64 relevant states
2025-01-21 16:11:54,365 - mdp.py - MDP has 5 actions
2025-01-21 16:11:54,366 - mdp.py - found the following 2 variables: ['X:[0..7]', 'Y:[0..7]']
2025-01-21 16:11:54,370 - decision_tree.py - the optimal scheduler has value: 0.41463913340435876
2025-01-21 16:11:54,370 - decision_tree.py - the random scheduler has value: 0.0010996088580579944

2025-01-21 16:11:54,370 - mdp.py - building tree of depth 0
2025-01-21 16:11:54,374 - statistic.py - synthesis initiated, design space: 5
2025-01-21 16:11:54,377 - synthesizer_ar.py - value 0.1584 achieved after 0.02 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.0 s
number of holes: 1, family size: 5, quotient: 64 states / 320 actions
explored: 100 %
MDP stats: avg MDP size: 50, iterations: 4

optimum: 0.158361
--------------------
2025-01-21 16:11:54,378 - decision_tree.py - families considered: 4
2025-01-21 16:11:54,378 - decision_tree.py - families skipped by construction: 0
2025-01-21 16:11:54,378 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 16:11:54,378 - decision_tree.py - families model checked: 4
2025-01-21 16:11:54,378 - decision_tree.py - harmonizations attempted: 1
2025-01-21 16:11:54,378 - decision_tree.py - harmonizations succeeded: 1

2025-01-21 16:11:54,378 - decision_tree.py - printing synthesized assignment below:
2025-01-21 16:11:54,378 - decision_tree.py - A_0=(Right)
2025-01-21 16:11:54,378 - decision_tree.py - double-checking specification satisfiability:  : 0.15836080489695326

2025-01-21 16:11:54,378 - mdp.py - building tree of depth 1
2025-01-21 16:11:54,384 - statistic.py - synthesis initiated, design space: 2450
2025-01-21 16:11:54,393 - synthesizer_ar.py - value 0.1842 achieved after 0.03 seconds
2025-01-21 16:11:54,396 - synthesizer_ar.py - value 0.2161 achieved after 0.03 seconds
2025-01-21 16:11:54,399 - synthesizer_ar.py - value 0.2575 achieved after 0.04 seconds
2025-01-21 16:11:54,401 - synthesizer_ar.py - value 0.3046 achieved after 0.04 seconds
2025-01-21 16:11:54,404 - synthesizer_ar.py - value 0.3069 achieved after 0.04 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.11 s
number of holes: 5, family size: 2450, quotient: 64 states / 320 actions
explored: 200 %
MDP stats: avg MDP size: 55, iterations: 86

optimum: 0.306862
--------------------
2025-01-21 16:11:54,492 - decision_tree.py - families considered: 86
2025-01-21 16:11:54,492 - decision_tree.py - families skipped by construction: 0
2025-01-21 16:11:54,492 - decision_tree.py - families with schedulers preserved: 11
2025-01-21 16:11:54,492 - decision_tree.py - families model checked: 75
2025-01-21 16:11:54,492 - decision_tree.py - harmonizations attempted: 24
2025-01-21 16:11:54,492 - decision_tree.py - harmonizations succeeded: 5

2025-01-21 16:11:54,492 - decision_tree.py - printing synthesized assignment below:
2025-01-21 16:11:54,492 - decision_tree.py - V_0=X, X_0=4, Y_0=0, A_1=(Up), A_2=(Right)
2025-01-21 16:11:54,492 - decision_tree.py - double-checking specification satisfiability:  : 0.3068621561890206

2025-01-21 16:11:54,493 - mdp.py - building tree of depth 2
2025-01-21 16:11:54,499 - statistic.py - synthesis initiated, design space: 1e8
2025-01-21 16:11:54,588 - synthesizer_ar.py - value 0.3536 achieved after 0.23 seconds
2025-01-21 16:11:54,649 - synthesizer_ar.py - value 0.3751 achieved after 0.29 seconds
2025-01-21 16:11:54,836 - synthesizer_ar.py - value 0.3845 achieved after 0.47 seconds
2025-01-21 16:11:55,303 - synthesizer_ar.py - value 0.387 achieved after 0.94 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.46 s
number of holes: 13, family size: 1e8, quotient: 64 states / 320 actions
explored: 107 %
MDP stats: avg MDP size: 59, iterations: 1130

optimum: 0.387012
--------------------
2025-01-21 16:11:56,955 - decision_tree.py - families considered: 1130
2025-01-21 16:11:56,955 - decision_tree.py - families skipped by construction: 0
2025-01-21 16:11:56,955 - decision_tree.py - families with schedulers preserved: 303
2025-01-21 16:11:56,955 - decision_tree.py - families model checked: 827
2025-01-21 16:11:56,955 - decision_tree.py - harmonizations attempted: 182
2025-01-21 16:11:56,955 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 16:11:56,955 - decision_tree.py - printing synthesized assignment below:
2025-01-21 16:11:56,955 - decision_tree.py - V_0=Y, X_0=0, Y_0=0, V_1=X, X_1=0, Y_1=0, A_2=(Up), A_3=(Right), V_4=X, X_4=5, Y_4=2, A_5=(Up), A_6=(Right)
2025-01-21 16:11:56,955 - decision_tree.py - double-checking specification satisfiability:  : 0.3870117876374776
2025-01-21 16:11:56,955 - decision_tree.py - the optimal scheduler has value: 0.41463913340435876
2025-01-21 16:11:56,955 - decision_tree.py - the random scheduler has value: 0.0010996088580579944
2025-01-21 16:11:56,956 - decision_tree.py - synthesized tree of depth 2 with 3 decision nodes
2025-01-21 16:11:56,956 - decision_tree.py - the synthesized tree has value 0.3870117876374776
2025-01-21 16:11:56,956 - decision_tree.py - the synthesized tree has relative value: 0.9331929740036543
2025-01-21 16:11:56,956 - decision_tree.py - printing the synthesized tree below:
if Y<=0:
  if X<=0:
    (Up)
  else:
    (Right)
else:
  if X<=5:
    (Up)
  else:
    (Right)

2025-01-21 16:11:56,956 - decision_tree.py - exported decision tree to logs/01-21-all/2/omdt-frozenlake_8x8/tree.dot
2025-01-21 16:11:57,000 - decision_tree.py - exported decision tree visualization to logs/01-21-all/2/omdt-frozenlake_8x8/tree.png
2025-01-21 16:11:57,000 - decision_tree.py - synthesis finished after 2.64 seconds

ColoringSmt = 0.002 s (0.1 %)
ColoringSmt:: create choice colors = 0.0 s (0.0 %)
ColoringSmt:: create harmonizing variants = 0.001 s (0.0 %)
areChoicesConsistent = 1.598 s (60.5 %)
areChoicesConsistent::1 is scheduler consistent? = 0.697 s (26.4 %)
areChoicesConsistent::2 better unsat core = 0.508 s (19.2 %)
areChoicesConsistent::3 unsat core analysis = 0.356 s (13.5 %)
check = 1.323 s (50.1 %)
loadUnsatCore = 0.002 s (0.1 %)
selectCompatibleChoices = 0.483 s (18.3 %)
selectCompatibleChoices::1 is family sat = 0.458 s (17.3 %)
selectCompatibleChoices::2 state exploration = 0.024 s (0.9 %)
