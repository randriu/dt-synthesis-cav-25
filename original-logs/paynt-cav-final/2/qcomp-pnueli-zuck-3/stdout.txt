2025-01-21 16:26:04,764 - cli.py - This is Paynt version 0.1.0.
2025-01-21 16:26:04,764 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/qcomp/pnueli-zuck-3/model-random-enabled.drn ...
2025-01-21 16:26:04,764 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 16:26:04,982 - sketch.py - assuming sketch in DRN format...
2025-01-21 16:26:05,343 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/qcomp/pnueli-zuck-3/discounted.props ...
2025-01-21 16:26:05,344 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 16:26:05,345 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/qcomp/pnueli-zuck-3/state-valuations.json, adding to the model...
2025-01-21 16:26:05,348 - sketch.py - sketch parsing OK
2025-01-21 16:26:05,722 - sketch.py - constructed explicit quotient having 1950 states and 122850 choices
2025-01-21 16:26:05,722 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 16:26:05,731 - mdp.py - MDP has 1949/1950 relevant states
2025-01-21 16:26:06,897 - mdp.py - MDP has 63 actions
2025-01-21 16:26:06,905 - mdp.py - found the following 3 variables: ['p0:[0..15]', 'p1:[1..10]', 'p2:[0..15]']
2025-01-21 16:26:06,922 - decision_tree.py - the optimal scheduler has value: 0.96059601
2025-01-21 16:26:06,926 - decision_tree.py - the random scheduler has value: 0.6489813220663848

2025-01-21 16:26:06,926 - mdp.py - building tree of depth 0
2025-01-21 16:26:07,005 - statistic.py - synthesis initiated, design space: 63
2025-01-21 16:26:07,064 - synthesizer_ar.py - value 0.7422 achieved after 2.3 seconds
2025-01-21 16:26:07,070 - synthesizer_ar.py - value 0.7439 achieved after 2.31 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.12 s
number of holes: 1, family size: 63, quotient: 1950 states / 122850 actions
explored: 100 %
MDP stats: avg MDP size: 1908, iterations: 43

optimum: 0.74395
--------------------
2025-01-21 16:26:08,127 - decision_tree.py - families considered: 43
2025-01-21 16:26:08,128 - decision_tree.py - families skipped by construction: 0
2025-01-21 16:26:08,128 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 16:26:08,128 - decision_tree.py - families model checked: 43
2025-01-21 16:26:08,128 - decision_tree.py - harmonizations attempted: 14
2025-01-21 16:26:08,128 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 16:26:08,128 - decision_tree.py - printing synthesized assignment below:
2025-01-21 16:26:08,128 - decision_tree.py - A_0=process1_cmd_27
2025-01-21 16:26:08,134 - decision_tree.py - double-checking specification satisfiability:  : 0.7439499353807243

2025-01-21 16:26:08,135 - mdp.py - building tree of depth 1
2025-01-21 16:26:08,435 - statistic.py - synthesis initiated, design space: 1e7
2025-01-21 16:26:09,279 - synthesizer_ar.py - value 0.7464 achieved after 4.52 seconds
> progress 0.108%, elapsed 3 s, estimated 2814 s, iters = {MDP: 69}, opt = 0.7464
2025-01-21 16:26:13,491 - synthesizer_ar.py - value 0.7466 achieved after 8.73 seconds
> progress 0.221%, elapsed 6 s, estimated 2739 s, iters = {MDP: 152}, opt = 0.7466
2025-01-21 16:26:14,695 - synthesizer_ar.py - value 0.7468 achieved after 9.93 seconds
2025-01-21 16:26:16,110 - synthesizer_ar.py - value 0.7473 achieved after 11.35 seconds
> progress 0.292%, elapsed 9 s, estimated 3107 s, iters = {MDP: 245}, opt = 0.7473
2025-01-21 16:26:17,865 - synthesizer_ar.py - value 0.75 achieved after 13.1 seconds
> progress 0.386%, elapsed 12 s, estimated 3133 s, iters = {MDP: 336}, opt = 0.75
> progress 0.438%, elapsed 15 s, estimated 3442 s, iters = {MDP: 436}, opt = 0.75
2025-01-21 16:26:26,099 - synthesizer_ar.py - value 0.8073 achieved after 21.34 seconds
> progress 0.572%, elapsed 18 s, estimated 3166 s, iters = {MDP: 541}, opt = 0.8073
> progress 2.393%, elapsed 21 s, estimated 883 s, iters = {MDP: 634}, opt = 0.8073
> progress 3.872%, elapsed 24 s, estimated 624 s, iters = {MDP: 723}, opt = 0.8073
> progress 13.009%, elapsed 27 s, estimated 208 s, iters = {MDP: 789}, opt = 0.8073
> progress 29.388%, elapsed 30 s, estimated 102 s, iters = {MDP: 857}, opt = 0.8073
> progress 29.786%, elapsed 33 s, estimated 111 s, iters = {MDP: 953}, opt = 0.8073
> progress 33.761%, elapsed 36 s, estimated 107 s, iters = {MDP: 1037}, opt = 0.8073
> progress 34.294%, elapsed 39 s, estimated 114 s, iters = {MDP: 1141}, opt = 0.8073
> progress 35.275%, elapsed 42 s, estimated 119 s, iters = {MDP: 1243}, opt = 0.8073
> progress 37.399%, elapsed 45 s, estimated 121 s, iters = {MDP: 1331}, opt = 0.8073
> progress 58.606%, elapsed 48 s, estimated 82 s, iters = {MDP: 1397}, opt = 0.8073
> progress 60.881%, elapsed 51 s, estimated 84 s, iters = {MDP: 1464}, opt = 0.8073
> progress 62.633%, elapsed 54 s, estimated 86 s, iters = {MDP: 1558}, opt = 0.8073
> progress 62.888%, elapsed 57 s, estimated 91 s, iters = {MDP: 1656}, opt = 0.8073
2025-01-21 16:27:08,048 - synthesizer_ar.py - value 0.8211 achieved after 63.28 seconds
> progress 67.195%, elapsed 60 s, estimated 89 s, iters = {MDP: 1740}, opt = 0.8211
2025-01-21 16:27:08,991 - synthesizer_ar.py - value 0.8212 achieved after 64.23 seconds
2025-01-21 16:27:09,022 - synthesizer_ar.py - value 0.8442 achieved after 64.26 seconds
> progress 100.576%, elapsed 63 s, estimated 63 s, iters = {MDP: 1828}, opt = 0.8442
> progress 103.927%, elapsed 66 s, estimated 63 s, iters = {MDP: 1919}, opt = 0.8442
> progress 129.426%, elapsed 69 s, estimated 53 s, iters = {MDP: 1986}, opt = 0.8442
> progress 134.294%, elapsed 72 s, estimated 53 s, iters = {MDP: 2084}, opt = 0.8442
> progress 158.857%, elapsed 75 s, estimated 47 s, iters = {MDP: 2149}, opt = 0.8442
> progress 167.085%, elapsed 78 s, estimated 46 s, iters = {MDP: 2235}, opt = 0.8442
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 80.63 s
number of holes: 6, family size: 1e7, quotient: 1950 states / 122850 actions
explored: 200 %
MDP stats: avg MDP size: 1892, iterations: 2293

optimum: 0.844248
--------------------
2025-01-21 16:27:29,066 - decision_tree.py - families considered: 2293
2025-01-21 16:27:29,066 - decision_tree.py - families skipped by construction: 0
2025-01-21 16:27:29,066 - decision_tree.py - families with schedulers preserved: 77
2025-01-21 16:27:29,066 - decision_tree.py - families model checked: 2216
2025-01-21 16:27:29,066 - decision_tree.py - harmonizations attempted: 724
2025-01-21 16:27:29,066 - decision_tree.py - harmonizations succeeded: 7

2025-01-21 16:27:29,066 - decision_tree.py - printing synthesized assignment below:
2025-01-21 16:27:29,066 - decision_tree.py - V_0=p1, p0_0=0, p1_0=1, p2_0=0, A_1=process1_cmd_26, A_2=process1_cmd_27
2025-01-21 16:27:29,073 - decision_tree.py - double-checking specification satisfiability:  : 0.8442479507270727

2025-01-21 16:27:29,073 - mdp.py - building tree of depth 2
2025-01-21 16:27:29,632 - statistic.py - synthesis initiated, design space: 1e18
2025-01-21 16:27:32,347 - synthesizer_ar.py - value 0.8587 achieved after 87.58 seconds
> progress 0.012%, elapsed 3 s, estimated 23609 s (6 hours), iters = {MDP: 59}, opt = 0.8587
2025-01-21 16:27:33,235 - synthesizer_ar.py - value 0.8599 achieved after 88.47 seconds
2025-01-21 16:27:34,895 - synthesizer_ar.py - value 0.8658 achieved after 90.13 seconds
> progress 0.9%, elapsed 6 s, estimated 674 s, iters = {MDP: 121}, opt = 0.8658
2025-01-21 16:27:35,724 - synthesizer_ar.py - value 0.9418 achieved after 90.96 seconds
> progress 3.611%, elapsed 9 s, estimated 251 s, iters = {MDP: 193}, opt = 0.9418
> progress 3.746%, elapsed 12 s, estimated 323 s, iters = {MDP: 262}, opt = 0.9418
> progress 3.797%, elapsed 15 s, estimated 397 s, iters = {MDP: 335}, opt = 0.9418
> progress 6.728%, elapsed 18 s, estimated 269 s, iters = {MDP: 406}, opt = 0.9418
> progress 9.145%, elapsed 21 s, estimated 231 s, iters = {MDP: 466}, opt = 0.9418
> progress 10.099%, elapsed 24 s, estimated 239 s, iters = {MDP: 532}, opt = 0.9418
> progress 10.344%, elapsed 27 s, estimated 262 s, iters = {MDP: 599}, opt = 0.9418
> progress 13.392%, elapsed 30 s, estimated 225 s, iters = {MDP: 672}, opt = 0.9418
> progress 13.587%, elapsed 33 s, estimated 244 s, iters = {MDP: 741}, opt = 0.9418
> progress 14.043%, elapsed 36 s, estimated 258 s, iters = {MDP: 812}, opt = 0.9418
> progress 22.175%, elapsed 39 s, estimated 177 s, iters = {MDP: 883}, opt = 0.9418
> progress 22.211%, elapsed 42 s, estimated 190 s, iters = {MDP: 951}, opt = 0.9418
> progress 22.248%, elapsed 45 s, estimated 204 s, iters = {MDP: 1027}, opt = 0.9418
> progress 22.283%, elapsed 48 s, estimated 217 s, iters = {MDP: 1110}, opt = 0.9418
> progress 26.767%, elapsed 51 s, estimated 192 s, iters = {MDP: 1176}, opt = 0.9418
2025-01-21 16:28:21,415 - synthesizer_ar.py - value 0.9606 achieved after 136.65 seconds
> progress 33.677%, elapsed 54 s, estimated 161 s, iters = {MDP: 1253}, opt = 0.9606
> progress 45.167%, elapsed 57 s, estimated 127 s, iters = {MDP: 1327}, opt = 0.9606
> progress 61.625%, elapsed 60 s, estimated 98 s, iters = {MDP: 1396}, opt = 0.9606
> progress 65.772%, elapsed 63 s, estimated 96 s, iters = {MDP: 1471}, opt = 0.9606
> progress 72.167%, elapsed 66 s, estimated 92 s, iters = {MDP: 1545}, opt = 0.9606
> progress 75.823%, elapsed 69 s, estimated 91 s, iters = {MDP: 1616}, opt = 0.9606
> progress 76.279%, elapsed 72 s, estimated 95 s, iters = {MDP: 1689}, opt = 0.9606
> progress 86.723%, elapsed 75 s, estimated 87 s, iters = {MDP: 1768}, opt = 0.9606
> progress 93.11%, elapsed 78 s, estimated 84 s, iters = {MDP: 1837}, opt = 0.9606
> progress 96.813%, elapsed 81 s, estimated 84 s, iters = {MDP: 1909}, opt = 0.9606
> progress 97.287%, elapsed 84 s, estimated 87 s, iters = {MDP: 1982}, opt = 0.9606
> progress 98.437%, elapsed 87 s, estimated 89 s, iters = {MDP: 2053}, opt = 0.9606
> progress 98.469%, elapsed 90 s, estimated 92 s, iters = {MDP: 2131}, opt = 0.9606
> progress 98.765%, elapsed 93 s, estimated 95 s, iters = {MDP: 2201}, opt = 0.9606
> progress 98.78%, elapsed 96 s, estimated 98 s, iters = {MDP: 2279}, opt = 0.9606
> progress 99.016%, elapsed 99 s, estimated 100 s, iters = {MDP: 2357}, opt = 0.9606
> progress 100.012%, elapsed 102 s, estimated 102 s, iters = {MDP: 2437}, opt = 0.9606
> progress 102.172%, elapsed 105 s, estimated 103 s, iters = {MDP: 2511}, opt = 0.9606
> progress 102.218%, elapsed 108 s, estimated 106 s, iters = {MDP: 2581}, opt = 0.9606
> progress 102.222%, elapsed 112 s, estimated 109 s, iters = {MDP: 2657}, opt = 0.9606
> progress 102.814%, elapsed 115 s, estimated 111 s, iters = {MDP: 2726}, opt = 0.9606
> progress 102.942%, elapsed 118 s, estimated 114 s, iters = {MDP: 2795}, opt = 0.9606
> progress 102.946%, elapsed 121 s, estimated 117 s, iters = {MDP: 2868}, opt = 0.9606
> progress 102.956%, elapsed 124 s, estimated 120 s, iters = {MDP: 2941}, opt = 0.9606
> progress 102.956%, elapsed 127 s, estimated 123 s, iters = {MDP: 3021}, opt = 0.9606
> progress 102.978%, elapsed 130 s, estimated 126 s, iters = {MDP: 3087}, opt = 0.9606
> progress 103.687%, elapsed 133 s, estimated 128 s, iters = {MDP: 3161}, opt = 0.9606
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 135.84 s
number of holes: 16, family size: 1e18, quotient: 1950 states / 122850 actions
explored: 103 %
MDP stats: avg MDP size: 1830, iterations: 3225

optimum: 0.960596
--------------------
2025-01-21 16:29:45,468 - decision_tree.py - families considered: 3225
2025-01-21 16:29:45,468 - decision_tree.py - families skipped by construction: 0
2025-01-21 16:29:45,468 - decision_tree.py - families with schedulers preserved: 1133
2025-01-21 16:29:45,468 - decision_tree.py - families model checked: 2092
2025-01-21 16:29:45,468 - decision_tree.py - harmonizations attempted: 116
2025-01-21 16:29:45,468 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 16:29:45,468 - decision_tree.py - printing synthesized assignment below:
2025-01-21 16:29:45,468 - decision_tree.py - V_0=p1, p0_0=1, p1_0=2, p2_0=0, V_1=p1, p0_1=0, p1_1=1, p2_1=0, A_2=process1_cmd_26, A_3=process1_cmd_27, V_4=p1, p0_4=0, p1_4=3, p2_4=0, A_5=process1_cmd_29, A_6=process1_cmd_32
2025-01-21 16:29:45,472 - decision_tree.py - double-checking specification satisfiability:  : 0.96059601
2025-01-21 16:29:45,472 - decision_tree.py - the optimal scheduler has value: 0.96059601
2025-01-21 16:29:45,472 - decision_tree.py - the random scheduler has value: 0.6489813220663848
2025-01-21 16:29:45,473 - decision_tree.py - synthesized tree of depth 2 with 3 decision nodes
2025-01-21 16:29:45,473 - decision_tree.py - the synthesized tree has value 0.96059601
2025-01-21 16:29:45,473 - decision_tree.py - the synthesized tree has relative value: 1.0
2025-01-21 16:29:45,473 - decision_tree.py - printing the synthesized tree below:
if p1<=2:
  if p1<=1:
    process1_cmd_26
  else:
    process1_cmd_27
else:
  if p1<=3:
    process1_cmd_29
  else:
    process1_cmd_32

2025-01-21 16:29:45,544 - decision_tree.py - exported decision tree to logs/01-21-all/2/qcomp-pnueli-zuck-3/tree.dot
2025-01-21 16:29:45,591 - decision_tree.py - exported decision tree visualization to logs/01-21-all/2/qcomp-pnueli-zuck-3/tree.png
2025-01-21 16:29:45,592 - decision_tree.py - synthesis finished after 220.83 seconds

ColoringSmt = 0.457 s (0.2 %)
ColoringSmt:: create choice colors = 0.208 s (0.1 %)
ColoringSmt:: create harmonizing variants = 0.248 s (0.1 %)
areChoicesConsistent = 12.435 s (5.6 %)
areChoicesConsistent::1 is scheduler consistent? = 7.324 s (3.3 %)
areChoicesConsistent::2 better unsat core = 2.598 s (1.2 %)
areChoicesConsistent::3 unsat core analysis = 2.454 s (1.1 %)
check = 9.277 s (4.2 %)
loadUnsatCore = 0.013 s (0.0 %)
selectCompatibleChoices = 28.375 s (12.8 %)
selectCompatibleChoices::1 is family sat = 16.34 s (7.4 %)
selectCompatibleChoices::2 state exploration = 12.032 s (5.4 %)
