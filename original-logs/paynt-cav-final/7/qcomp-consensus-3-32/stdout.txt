2025-01-21 20:10:24,459 - cli.py - This is Paynt version 0.1.0.
2025-01-21 20:10:24,459 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/qcomp/consensus-3-32/model-random-enabled.drn ...
2025-01-21 20:10:24,459 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 20:10:24,560 - sketch.py - assuming sketch in DRN format...
2025-01-21 20:10:25,114 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/qcomp/consensus-3-32/discounted.props ...
2025-01-21 20:10:25,114 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=9999/10000] 
2025-01-21 20:10:25,128 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/qcomp/consensus-3-32/state-valuations.json, adding to the model...
2025-01-21 20:10:25,134 - sketch.py - sketch parsing OK
2025-01-21 20:10:25,205 - sketch.py - constructed explicit quotient having 6161 states and 86254 choices
2025-01-21 20:10:25,205 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=9999/10000] 
2025-01-21 20:10:25,220 - mdp.py - MDP has 6154/6161 relevant states
2025-01-21 20:10:25,443 - mdp.py - MDP has 14 actions
2025-01-21 20:10:25,483 - mdp.py - found the following 5 variables: ['coin1:[0..1]', 'coin2:[0..1]', 'counter:[2..196]', 'pc1:[0..3]', 'pc2:[0..3]']
2025-01-21 20:10:26,983 - decision_tree.py - the optimal scheduler has value: 0.09439378652811341
2025-01-21 20:10:27,100 - decision_tree.py - the random scheduler has value: 0.09346270146188901

2025-01-21 20:10:27,100 - mdp.py - building tree of depth 0
2025-01-21 20:10:27,177 - statistic.py - synthesis initiated, design space: 14
2025-01-21 20:10:28,817 - synthesizer_ar.py - value 0.0935 achieved after 4.36 seconds
2025-01-21 20:10:30,704 - synthesizer_ar.py - value 0.0936 achieved after 6.24 seconds
> progress 14.285%, elapsed 3 s, estimated 24 s, iters = {MDP: 5}, opt = 0.0936
> progress 50.0%, elapsed 6 s, estimated 13 s, iters = {MDP: 12}, opt = 0.0936
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=9999/10000] 

method: AR (decision tree), synthesis time: 8.19 s
number of holes: 1, family size: 14, quotient: 6161 states / 86254 actions
explored: 100 %
MDP stats: avg MDP size: 6160, iterations: 16

optimum: 0.093622
--------------------
2025-01-21 20:10:35,365 - decision_tree.py - families considered: 16
2025-01-21 20:10:35,365 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:10:35,365 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 20:10:35,365 - decision_tree.py - families model checked: 16
2025-01-21 20:10:35,365 - decision_tree.py - harmonizations attempted: 5
2025-01-21 20:10:35,365 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 20:10:35,365 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:10:35,365 - decision_tree.py - A_0=process2_cmd_8
2025-01-21 20:10:35,472 - decision_tree.py - double-checking specification satisfiability:  : 0.09362211253869995

2025-01-21 20:10:35,472 - mdp.py - building tree of depth 1
2025-01-21 20:10:35,807 - statistic.py - synthesis initiated, design space: 1e6
> progress 0.204%, elapsed 4 s, estimated 1962 s, iters = {MDP: 7}, opt = 0.0936
> progress 0.816%, elapsed 7 s, estimated 858 s, iters = {MDP: 11}, opt = 0.0936
> progress 0.819%, elapsed 10 s, estimated 1230 s, iters = {MDP: 21}, opt = 0.0936
> progress 0.821%, elapsed 13 s, estimated 1600 s, iters = {MDP: 30}, opt = 0.0936
> progress 0.824%, elapsed 16 s, estimated 1997 s, iters = {MDP: 40}, opt = 0.0936
> progress 0.826%, elapsed 19 s, estimated 2409 s, iters = {MDP: 50}, opt = 0.0936
> progress 0.829%, elapsed 22 s, estimated 2766 s, iters = {MDP: 59}, opt = 0.0936
> progress 0.831%, elapsed 26 s, estimated 3197 s, iters = {MDP: 68}, opt = 0.0936
> progress 0.833%, elapsed 29 s, estimated 3565 s, iters = {MDP: 76}, opt = 0.0936
> progress 0.835%, elapsed 33 s, estimated 3952 s, iters = {MDP: 84}, opt = 0.0936
> progress 0.837%, elapsed 36 s, estimated 4360 s, iters = {MDP: 92}, opt = 0.0936
> progress 0.839%, elapsed 40 s, estimated 4785 s, iters = {MDP: 100}, opt = 0.0936
> progress 0.842%, elapsed 44 s, estimated 5229 s, iters = {MDP: 108}, opt = 0.0936
> progress 0.843%, elapsed 47 s, estimated 5578 s, iters = {MDP: 114}, opt = 0.0936
> progress 0.845%, elapsed 50 s, estimated 5938 s, iters = {MDP: 120}, opt = 0.0936
> progress 0.846%, elapsed 53 s, estimated 6312 s, iters = {MDP: 126}, opt = 0.0936
> progress 0.848%, elapsed 56 s, estimated 6696 s, iters = {MDP: 132}, opt = 0.0936
> progress 0.849%, elapsed 60 s, estimated 7091 s, iters = {MDP: 138}, opt = 0.0936
> progress 0.851%, elapsed 63 s, estimated 7493 s (2 hours), iters = {MDP: 144}, opt = 0.0936
> progress 0.853%, elapsed 67 s, estimated 7909 s (2 hours), iters = {MDP: 150}, opt = 0.0936
> progress 0.854%, elapsed 71 s, estimated 8348 s (2 hours), iters = {MDP: 156}, opt = 0.0936
> progress 0.856%, elapsed 75 s, estimated 8814 s (2 hours), iters = {MDP: 162}, opt = 0.0936
> progress 0.857%, elapsed 79 s, estimated 9291 s (2 hours), iters = {MDP: 168}, opt = 0.0936
> progress 0.859%, elapsed 82 s, estimated 9627 s (2 hours), iters = {MDP: 173}, opt = 0.0936
2025-01-21 20:12:01,549 - synthesizer.py - time limit reached, aborting...
2025-01-21 20:12:01,549 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=9999/10000] 

method: AR (decision tree), synthesis time: 85.74 s
number of holes: 8, family size: 1e6, quotient: 6161 states / 86254 actions
explored: 0 %
MDP stats: avg MDP size: 6158, iterations: 176

optimum: 0.093622
--------------------
2025-01-21 20:12:01,549 - decision_tree.py - families considered: 176
2025-01-21 20:12:01,549 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:12:01,549 - decision_tree.py - families with schedulers preserved: 2
2025-01-21 20:12:01,549 - decision_tree.py - families model checked: 174
2025-01-21 20:12:01,549 - decision_tree.py - harmonizations attempted: 87
2025-01-21 20:12:01,549 - decision_tree.py - harmonizations succeeded: 0


2025-01-21 20:12:01,549 - mdp.py - building tree of depth 2
2025-01-21 20:12:02,394 - statistic.py - synthesis initiated, design space: 1e16
> progress 0.0%, elapsed 4 s, estimated 4126221 s (47 days), iters = {MDP: 5}, opt = 0.0936
> progress 0.004%, elapsed 7 s, estimated 183356 s (2 days), iters = {MDP: 12}, opt = 0.0936
> progress 0.004%, elapsed 10 s, estimated 219985 s (2 days), iters = {MDP: 16}, opt = 0.0936
> progress 0.007%, elapsed 14 s, estimated 187707 s (2 days), iters = {MDP: 22}, opt = 0.0936
> progress 0.008%, elapsed 17 s, estimated 211884 s (2 days), iters = {MDP: 27}, opt = 0.0936
> progress 0.009%, elapsed 21 s, estimated 230080 s (2 days), iters = {MDP: 35}, opt = 0.0936
> progress 0.009%, elapsed 25 s, estimated 256292 s (2 days), iters = {MDP: 43}, opt = 0.0936
> progress 0.009%, elapsed 28 s, estimated 288264 s (3 days), iters = {MDP: 48}, opt = 0.0936
> progress 0.009%, elapsed 32 s, estimated 327329 s (3 days), iters = {MDP: 55}, opt = 0.0936
> progress 0.01%, elapsed 35 s, estimated 354092 s (4 days), iters = {MDP: 63}, opt = 0.0936
> progress 0.01%, elapsed 40 s, estimated 386319 s (4 days), iters = {MDP: 69}, opt = 0.0936
> progress 0.011%, elapsed 43 s, estimated 396705 s (4 days), iters = {MDP: 73}, opt = 0.0936
> progress 0.011%, elapsed 46 s, estimated 402435 s (4 days), iters = {MDP: 78}, opt = 0.0936
> progress 0.013%, elapsed 50 s, estimated 381995 s (4 days), iters = {MDP: 83}, opt = 0.0936
> progress 0.014%, elapsed 53 s, estimated 378809 s (4 days), iters = {MDP: 90}, opt = 0.0936
> progress 0.014%, elapsed 56 s, estimated 403031 s (4 days), iters = {MDP: 94}, opt = 0.0936
> progress 0.014%, elapsed 60 s, estimated 425849 s (4 days), iters = {MDP: 100}, opt = 0.0936
> progress 0.014%, elapsed 63 s, estimated 448445 s (5 days), iters = {MDP: 105}, opt = 0.0936
> progress 0.014%, elapsed 67 s, estimated 475509 s (5 days), iters = {MDP: 111}, opt = 0.0936
> progress 0.014%, elapsed 71 s, estimated 498576 s (5 days), iters = {MDP: 116}, opt = 0.0936
> progress 0.014%, elapsed 74 s, estimated 525234 s (6 days), iters = {MDP: 122}, opt = 0.0936
> progress 0.014%, elapsed 78 s, estimated 548527 s (6 days), iters = {MDP: 128}, opt = 0.0936
> progress 0.014%, elapsed 82 s, estimated 574386 s (6 days), iters = {MDP: 133}, opt = 0.0936
> progress 0.014%, elapsed 85 s, estimated 597148 s (6 days), iters = {MDP: 138}, opt = 0.0936
2025-01-21 20:13:28,382 - synthesizer.py - time limit reached, aborting...
2025-01-21 20:13:28,382 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=9999/10000] 

method: AR (decision tree), synthesis time: 85.99 s
number of holes: 22, family size: 1e16, quotient: 6161 states / 86254 actions
explored: 0 %
MDP stats: avg MDP size: 6131, iterations: 138

optimum: 0.093622
--------------------
2025-01-21 20:13:28,382 - decision_tree.py - families considered: 138
2025-01-21 20:13:28,382 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:13:28,382 - decision_tree.py - families with schedulers preserved: 12
2025-01-21 20:13:28,382 - decision_tree.py - families model checked: 126
2025-01-21 20:13:28,382 - decision_tree.py - harmonizations attempted: 44
2025-01-21 20:13:28,382 - decision_tree.py - harmonizations succeeded: 0


2025-01-21 20:13:28,382 - mdp.py - building tree of depth 3
2025-01-21 20:13:30,193 - statistic.py - synthesis initiated, design space: 1e36
> progress 0.0%, elapsed 3 s, estimated 3325418 s (38 days), iters = {MDP: 4}, opt = 0.0936
> progress 0.0%, elapsed 6 s, estimated 6534753 s (75 days), iters = {MDP: 7}, opt = 0.0936
> progress 0.0%, elapsed 10 s, estimated 11376281 s (131 days), iters = {MDP: 13}, opt = 0.0936
> progress 0.0%, elapsed 13 s, estimated 4566920 s (52 days), iters = {MDP: 19}, opt = 0.0936
> progress 0.0%, elapsed 17 s, estimated 3579746 s (41 days), iters = {MDP: 26}, opt = 0.0936
> progress 0.0%, elapsed 21 s, estimated 3924922 s (45 days), iters = {MDP: 32}, opt = 0.0936
> progress 0.0%, elapsed 24 s, estimated 3860603 s (44 days), iters = {MDP: 38}, opt = 0.0936
2025-01-21 20:13:57,824 - synthesizer_ar.py - value 0.0939 achieved after 213.37 seconds
> progress 0.0%, elapsed 27 s, estimated 4419081 s (51 days), iters = {MDP: 42}, opt = 0.0939
> progress 0.0%, elapsed 31 s, estimated 5079630 s (58 days), iters = {MDP: 49}, opt = 0.0939
> progress 0.0%, elapsed 35 s, estimated 5603672 s (64 days), iters = {MDP: 54}, opt = 0.0939
> progress 0.0%, elapsed 38 s, estimated 6177577 s (71 days), iters = {MDP: 59}, opt = 0.0939
> progress 0.0%, elapsed 42 s, estimated 6762316 s (78 days), iters = {MDP: 65}, opt = 0.0939
> progress 0.0%, elapsed 45 s, estimated 7267868 s (84 days), iters = {MDP: 70}, opt = 0.0939
> progress 0.0%, elapsed 49 s, estimated 7931547 s (91 days), iters = {MDP: 76}, opt = 0.0939
> progress 0.0%, elapsed 53 s, estimated 8444507 s (97 days), iters = {MDP: 81}, opt = 0.0939
> progress 0.0%, elapsed 57 s, estimated 9060942 s (104 days), iters = {MDP: 86}, opt = 0.0939
> progress 0.0%, elapsed 61 s, estimated 9706902 s (112 days), iters = {MDP: 93}, opt = 0.0939
> progress 0.0%, elapsed 64 s, estimated 10171259 s (117 days), iters = {MDP: 96}, opt = 0.0939
> progress 0.0%, elapsed 68 s, estimated 10610679 s (122 days), iters = {MDP: 101}, opt = 0.0939
> progress 0.0%, elapsed 72 s, estimated 11274352 s (130 days), iters = {MDP: 106}, opt = 0.0939
> progress 0.0%, elapsed 75 s, estimated 11822377 s (136 days), iters = {MDP: 110}, opt = 0.0939
> progress 0.0%, elapsed 79 s, estimated 12374015 s (143 days), iters = {MDP: 115}, opt = 0.0939
> progress 0.0%, elapsed 82 s, estimated 12902269 s (149 days), iters = {MDP: 118}, opt = 0.0939
2025-01-21 20:14:57,007 - synthesizer.py - time limit reached, aborting...
2025-01-21 20:14:57,007 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=9999/10000] 

method: AR (decision tree), synthesis time: 86.81 s
number of holes: 50, family size: 1e36, quotient: 6161 states / 86254 actions
explored: 0 %
MDP stats: avg MDP size: 6134, iterations: 123

optimum: 0.093887
--------------------
2025-01-21 20:14:57,007 - decision_tree.py - families considered: 123
2025-01-21 20:14:57,007 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:14:57,007 - decision_tree.py - families with schedulers preserved: 20
2025-01-21 20:14:57,007 - decision_tree.py - families model checked: 103
2025-01-21 20:14:57,007 - decision_tree.py - harmonizations attempted: 35
2025-01-21 20:14:57,007 - decision_tree.py - harmonizations succeeded: 1

2025-01-21 20:14:57,007 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:14:57,007 - decision_tree.py - V_0=pc2, coin1_0=0, coin2_0=0, counter_0=2, pc1_0=0, pc2_0=2, V_1=pc2, coin1_1=0, coin2_1=0, counter_1=2, pc1_1=0, pc2_1=1, V_2=pc2, coin1_2=0, coin2_2=0, counter_2=2, pc1_2=0, pc2_2=0, A_3=process1_cmd_0, A_4=process2_cmd_8, V_5=pc1, coin1_5=0, coin2_5=0, counter_5=100, pc1_5=0, pc2_5=0, A_6=process1_cmd_5, A_7=process1_cmd_1, V_8=pc1, coin1_8=0, coin2_8=0, counter_8=195, pc1_8=0, pc2_8=0, V_9=pc1, coin1_9=0, coin2_9=0, counter_9=2, pc1_9=2, pc2_9=0, A_10=__random__, A_11=__random__, V_12=counter, coin1_12=0, coin2_12=0, counter_12=195, pc1_12=0, pc2_12=0, A_13=__random__, A_14=__random__
2025-01-21 20:14:57,115 - decision_tree.py - double-checking specification satisfiability:  : 0.09388703237211474

2025-01-21 20:14:57,116 - mdp.py - building tree of depth 4
2025-01-21 20:15:01,309 - statistic.py - synthesis initiated, design space: 1e77
> progress 0.0%, elapsed 3 s, estimated 3851048 s (44 days), iters = {MDP: 4}, opt = 0.0939
> progress 0.0%, elapsed 7 s, estimated 7189101 s (83 days), iters = {MDP: 9}, opt = 0.0939
> progress 0.0%, elapsed 10 s, estimated 415193011625634944 s (13165684031 years), iters = {MDP: 14}, opt = 0.0939
> progress 0.0%, elapsed 14 s, estimated 164683336314063520 s (5222074337 years), iters = {MDP: 19}, opt = 0.0939
> progress 0.0%, elapsed 17 s, estimated 156791171408241248 s (4971815430 years), iters = {MDP: 24}, opt = 0.0939
> progress 0.0%, elapsed 21 s, estimated 65200673273079056 s (2067499786 years), iters = {MDP: 28}, opt = 0.0939
> progress 0.0%, elapsed 24 s, estimated 74622672583642816 s (2366269424 years), iters = {MDP: 32}, opt = 0.0939
> progress 0.0%, elapsed 28 s, estimated 86452081889793520 s (2741377533 years), iters = {MDP: 37}, opt = 0.0939
> progress 0.0%, elapsed 31 s, estimated 96102679973054304 s (3047395991 years), iters = {MDP: 42}, opt = 0.0939
> progress 0.0%, elapsed 34 s, estimated 104257608983796208 s (3305987093 years), iters = {MDP: 47}, opt = 0.0939
> progress 0.0%, elapsed 38 s, estimated 113890867907077216 s (3611455730 years), iters = {MDP: 53}, opt = 0.0939
> progress 0.0%, elapsed 42 s, estimated 125794100821900256 s (3988904769 years), iters = {MDP: 59}, opt = 0.0939
> progress 0.0%, elapsed 45 s, estimated 136155138591476288 s (4317451122 years), iters = {MDP: 65}, opt = 0.0939
> progress 0.0%, elapsed 48 s, estimated 146040505123863264 s (4630914038 years), iters = {MDP: 69}, opt = 0.0939
> progress 0.0%, elapsed 51 s, estimated 154951748266561856 s (4913487705 years), iters = {MDP: 74}, opt = 0.0939
> progress 0.0%, elapsed 54 s, estimated 164053595242684896 s (5202105379 years), iters = {MDP: 79}, opt = 0.0939
> progress 0.0%, elapsed 58 s, estimated 174490970515287104 s (5533072378 years), iters = {MDP: 85}, opt = 0.0939
> progress 0.0%, elapsed 62 s, estimated 185887418348447712 s (5894451368 years), iters = {MDP: 90}, opt = 0.0939
> progress 0.0%, elapsed 65 s, estimated 195044947741660384 s (6184834720 years), iters = {MDP: 95}, opt = 0.0939
> progress 0.0%, elapsed 68 s, estimated 204488962679279168 s (6484302469 years), iters = {MDP: 100}, opt = 0.0939
> progress 0.0%, elapsed 71 s, estimated 213712191381344160 s (6776769133 years), iters = {MDP: 105}, opt = 0.0939
> progress 0.0%, elapsed 74 s, estimated 223187380330339904 s (7077225403 years), iters = {MDP: 109}, opt = 0.0939
> progress 0.0%, elapsed 78 s, estimated 232992817283075904 s (7388153769 years), iters = {MDP: 114}, opt = 0.0939
> progress 0.0%, elapsed 81 s, estimated 241969072983965632 s (7672788970 years), iters = {MDP: 119}, opt = 0.0939
> progress 0.0%, elapsed 84 s, estimated 251506703937358368 s (7975225264 years), iters = {MDP: 123}, opt = 0.0939
2025-01-21 20:16:27,238 - synthesizer.py - time limit reached, aborting...
2025-01-21 20:16:27,239 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=9999/10000] 

method: AR (decision tree), synthesis time: 85.93 s
number of holes: 106, family size: 1e77, quotient: 6161 states / 86254 actions
explored: 0 %
MDP stats: avg MDP size: 6008, iterations: 125

optimum: 0.093887
--------------------
2025-01-21 20:16:27,240 - decision_tree.py - families considered: 125
2025-01-21 20:16:27,240 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:16:27,240 - decision_tree.py - families with schedulers preserved: 14
2025-01-21 20:16:27,240 - decision_tree.py - families model checked: 111
2025-01-21 20:16:27,240 - decision_tree.py - harmonizations attempted: 35
2025-01-21 20:16:27,240 - decision_tree.py - harmonizations succeeded: 0


2025-01-21 20:16:27,240 - mdp.py - building tree of depth 5
2025-01-21 20:16:35,911 - statistic.py - synthesis initiated, design space: 1e158
> progress 0.0%, elapsed 3 s, estimated 3127721 s (36 days), iters = {MDP: 4}, opt = 0.0939
> progress 0.0%, elapsed 6 s, estimated 6488418 s (75 days), iters = {MDP: 7}, opt = 0.0939
> progress 0.0%, elapsed 10 s, estimated 10132661 s (117 days), iters = {MDP: 12}, opt = 0.0939
> progress 0.0%, elapsed 13 s, estimated 40863287837420851036160 s (1295766357097312 years), iters = {MDP: 20}, opt = 0.0939
> progress 0.0%, elapsed 17 s, estimated 16723266325202606227456 s (530291296461269 years), iters = {MDP: 23}, opt = 0.0939
> progress 0.0%, elapsed 21 s, estimated 15551057930383806955520 s (493120812099943 years), iters = {MDP: 26}, opt = 0.0939
> progress 0.0%, elapsed 24 s, estimated 17778888342624886849536 s (563764851047212 years), iters = {MDP: 28}, opt = 0.0939
> progress 0.0%, elapsed 27 s, estimated 20159472265383620116480 s (639252672037786 years), iters = {MDP: 31}, opt = 0.0939
2025-01-21 20:17:06,945 - synthesizer_ar.py - value 0.0943 achieved after 402.49 seconds
> progress 0.0%, elapsed 31 s, estimated 22628116740205707264000 s (717532874816264 years), iters = {MDP: 37}, opt = 0.0943
> progress 0.0%, elapsed 34 s, estimated 25097785632387684630528 s (795845561656129 years), iters = {MDP: 45}, opt = 0.0943
> progress 0.0%, elapsed 37 s, estimated 27402517699431967490048 s (868928136080415 years), iters = {MDP: 52}, opt = 0.0943
> progress 0.0%, elapsed 40 s, estimated 29765161381548989087744 s (943847075772101 years), iters = {MDP: 59}, opt = 0.0943
> progress 0.0%, elapsed 44 s, estimated 32094234371220387659776 s (1017701495789586 years), iters = {MDP: 66}, opt = 0.0943
> progress 0.0%, elapsed 47 s, estimated 34539072890134637576192 s (1095226816658251 years), iters = {MDP: 73}, opt = 0.0943
> progress 0.0%, elapsed 50 s, estimated 36932840263740555264000 s (1171132682132818 years), iters = {MDP: 80}, opt = 0.0943
> progress 0.0%, elapsed 54 s, estimated 39339700957893317623808 s (1247453734078301 years), iters = {MDP: 87}, opt = 0.0943
> progress 0.0%, elapsed 57 s, estimated 41799816965834831560704 s (1325463500946056 years), iters = {MDP: 94}, opt = 0.0943
> progress 0.0%, elapsed 60 s, estimated 44210054985388174344192 s (1401891647177453 years), iters = {MDP: 101}, opt = 0.0943
> progress 0.0%, elapsed 64 s, estimated 46601574351762920308736 s (1477726228810341 years), iters = {MDP: 108}, opt = 0.0943
> progress 0.0%, elapsed 67 s, estimated 49086349194408996372480 s (1556517922197139 years), iters = {MDP: 115}, opt = 0.0943
> progress 0.0%, elapsed 70 s, estimated 51496780781442884960256 s (1632952206413079 years), iters = {MDP: 122}, opt = 0.0943
> progress 0.0%, elapsed 73 s, estimated 53865956681889345437696 s (1708078281389185 years), iters = {MDP: 129}, opt = 0.0943
> progress 0.0%, elapsed 77 s, estimated 56345757261063291666432 s (1786712241916010 years), iters = {MDP: 136}, opt = 0.0943
> progress 0.0%, elapsed 80 s, estimated 58818450250557625991168 s (1865120822252588 years), iters = {MDP: 143}, opt = 0.0943
> progress 0.0%, elapsed 84 s, estimated 61210622222528715685888 s (1940976097873183 years), iters = {MDP: 150}, opt = 0.0943
2025-01-21 20:18:01,836 - synthesizer.py - time limit reached, aborting...
2025-01-21 20:18:01,838 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=9999/10000] 

method: AR (decision tree), synthesis time: 85.93 s
number of holes: 218, family size: 1e158, quotient: 6161 states / 86254 actions
explored: 0 %
MDP stats: avg MDP size: 6064, iterations: 153

optimum: 0.094332
--------------------
2025-01-21 20:18:01,839 - decision_tree.py - families considered: 153
2025-01-21 20:18:01,839 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:18:01,839 - decision_tree.py - families with schedulers preserved: 61
2025-01-21 20:18:01,839 - decision_tree.py - families model checked: 92
2025-01-21 20:18:01,839 - decision_tree.py - harmonizations attempted: 11
2025-01-21 20:18:01,839 - decision_tree.py - harmonizations succeeded: 1

2025-01-21 20:18:01,839 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:18:01,839 - decision_tree.py - V_0=pc2, coin1_0=0, coin2_0=0, counter_0=2, pc1_0=0, pc2_0=2, V_1=pc2, coin1_1=0, coin2_1=0, counter_1=2, pc1_1=0, pc2_1=1, V_2=pc2, coin1_2=0, coin2_2=0, counter_2=2, pc1_2=0, pc2_2=0, V_3=pc2, coin1_3=0, coin2_3=0, counter_3=2, pc1_3=0, pc2_3=0, V_4=pc2, coin1_4=0, coin2_4=0, counter_4=2, pc1_4=0, pc2_4=0, A_5=process1_cmd_0, A_6=process2_cmd_10, V_7=coin2, coin1_7=0, coin2_7=0, counter_7=2, pc1_7=0, pc2_7=0, A_8=process1_cmd_1, A_9=process2_cmd_9, V_10=pc2, coin1_10=0, coin2_10=0, counter_10=2, pc1_10=0, pc2_10=1, V_11=counter, coin1_11=0, coin2_11=0, counter_11=113, pc1_11=0, pc2_11=0, A_12=process2_cmd_9, A_13=process2_cmd_8, V_14=pc2, coin1_14=0, coin2_14=0, counter_14=100, pc1_14=0, pc2_14=0, A_15=process1_cmd_5, A_16=__random__, V_17=pc1, coin1_17=0, coin2_17=0, counter_17=2, pc1_17=0, pc2_17=0, V_18=pc1, coin1_18=0, coin2_18=0, counter_18=2, pc1_18=0, pc2_18=0, V_19=pc2, coin1_19=0, coin2_19=0, counter_19=2, pc1_19=0, pc2_19=2, A_20=process1_cmd_0, A_21=process2_cmd_10, V_22=coin1, coin1_22=0, coin2_22=0, counter_22=2, pc1_22=0, pc2_22=0, A_23=__random__, A_24=__random__, V_25=pc1, coin1_25=0, coin2_25=0, counter_25=2, pc1_25=1, pc2_25=0, V_26=pc2, coin1_26=0, coin2_26=0, counter_26=2, pc1_26=2, pc2_26=2, A_27=process1_cmd_1, A_28=__random__, V_29=pc2, coin1_29=0, coin2_29=0, counter_29=2, pc1_29=0, pc2_29=2, A_30=process1_cmd_5, A_31=__random__, V_32=pc1, coin1_32=0, coin2_32=0, counter_32=2, pc1_32=0, pc2_32=0, V_33=pc1, coin1_33=0, coin2_33=0, counter_33=2, pc1_33=2, pc2_33=0, V_34=counter, coin1_34=0, coin2_34=0, counter_34=194, pc1_34=0, pc2_34=0, V_35=counter, coin1_35=0, coin2_35=0, counter_35=194, pc1_35=0, pc2_35=0, A_36=process1_cmd_4, A_37=__random__, V_38=coin2, coin1_38=0, coin2_38=0, counter_38=194, pc1_38=0, pc2_38=0, A_39=process1_cmd_0, A_40=process2_cmd_12, V_41=coin1, coin1_41=0, coin2_41=0, counter_41=2, pc1_41=0, pc2_41=0, V_42=counter, coin1_42=0, coin2_42=0, counter_42=2, pc1_42=0, pc2_42=0, A_43=__random__, A_44=done, V_45=coin1, coin1_45=0, coin2_45=0, counter_45=2, pc1_45=0, pc2_45=0, A_46=__random__, A_47=__random__, V_48=counter, coin1_48=0, coin2_48=0, counter_48=195, pc1_48=0, pc2_48=0, V_49=coin2, coin1_49=0, coin2_49=0, counter_49=195, pc1_49=0, pc2_49=0, V_50=counter, coin1_50=0, coin2_50=0, counter_50=195, pc1_50=0, pc2_50=0, A_51=process1_cmd_4, A_52=process1_cmd_3, V_53=pc1, coin1_53=0, coin2_53=0, counter_53=195, pc1_53=0, pc2_53=0, A_54=process1_cmd_5, A_55=done, V_56=coin1, coin1_56=0, coin2_56=0, counter_56=2, pc1_56=0, pc2_56=0, V_57=pc1, coin1_57=0, coin2_57=0, counter_57=2, pc1_57=0, pc2_57=0, A_58=__random__, A_59=process1_cmd_5, V_60=counter, coin1_60=0, coin2_60=0, counter_60=2, pc1_60=2, pc2_60=0, A_61=__random__, A_62=__random__
2025-01-21 20:18:01,966 - decision_tree.py - double-checking specification satisfiability:  : 0.09433193141449173
2025-01-21 20:18:01,967 - decision_tree.py - the optimal scheduler has value: 0.09439378652811341
2025-01-21 20:18:01,967 - decision_tree.py - the random scheduler has value: 0.09346270146188901
2025-01-21 20:18:01,969 - decision_tree.py - synthesized tree of depth 4 with 10 decision nodes
2025-01-21 20:18:01,969 - decision_tree.py - the synthesized tree has value 0.09433193141449173
2025-01-21 20:18:01,969 - decision_tree.py - the synthesized tree has relative value: 0.9335666354605955
2025-01-21 20:18:01,969 - decision_tree.py - printing the synthesized tree below:
if pc2<=2:
  if pc2<=1:
    if pc2<=0:
      process1_cmd_0
    else:
      if counter<=113:
        process2_cmd_9
      else:
        process2_cmd_8
  else:
    if pc1<=0:
      process1_cmd_0
    else:
      if pc1<=1:
        process1_cmd_1
      else:
        process1_cmd_5
else:
  if pc1<=0:
    if counter<=194:
      process1_cmd_4
    else:
      process2_cmd_12
  else:
    if counter<=195:
      if coin2<=0:
        process1_cmd_4
      else:
        done
    else:
      process1_cmd_5

2025-01-21 20:18:01,970 - decision_tree.py - exported decision tree to logs/01-21-all/7/qcomp-consensus-3-32/tree.dot
2025-01-21 20:18:02,044 - decision_tree.py - exported decision tree visualization to logs/01-21-all/7/qcomp-consensus-3-32/tree.png
2025-01-21 20:18:02,044 - decision_tree.py - synthesis finished after 457.58 seconds

ColoringSmt = 8.189 s (1.8 %)
ColoringSmt:: create choice colors = 2.341 s (0.5 %)
ColoringSmt:: create harmonizing variants = 5.843 s (1.3 %)
areChoicesConsistent = 30.891 s (6.8 %)
areChoicesConsistent::1 is scheduler consistent? = 25.007 s (5.5 %)
areChoicesConsistent::2 better unsat core = 4.171 s (0.9 %)
areChoicesConsistent::3 unsat core analysis = 0.503 s (0.1 %)
check = 23.075 s (5.0 %)
loadUnsatCore = 0.001 s (0.0 %)
selectCompatibleChoices = 7.04 s (1.5 %)
selectCompatibleChoices::1 is family sat = 4.845 s (1.1 %)
selectCompatibleChoices::2 state exploration = 2.194 s (0.5 %)
