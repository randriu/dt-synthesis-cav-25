2025-01-21 20:20:56,931 - cli.py - This is Paynt version 0.1.0.
2025-01-21 20:20:56,931 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/qcomp/resource-gathering-5/model-random-enabled.drn ...
2025-01-21 20:20:56,931 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 20:20:56,953 - sketch.py - assuming sketch in DRN format...
2025-01-21 20:20:56,975 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/qcomp/resource-gathering-5/discounted.props ...
2025-01-21 20:20:56,976 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 20:20:56,980 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/qcomp/resource-gathering-5/state-valuations.json, adding to the model...
2025-01-21 20:20:56,983 - sketch.py - sketch parsing OK
2025-01-21 20:20:56,987 - sketch.py - constructed explicit quotient having 3292 states and 16460 choices
2025-01-21 20:20:56,987 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 20:20:56,994 - mdp.py - MDP has 3291/3292 relevant states
2025-01-21 20:20:57,014 - mdp.py - MDP has 5 actions
2025-01-21 20:20:57,031 - mdp.py - found the following 7 variables: ['attacked:[0..1]', 'gem:[0..1]', 'gold:[0..1]', 'required_gem:[0..5]', 'required_gold:[0..5]', 'x:[1..5]', 'y:[1..5]']
2025-01-21 20:20:57,036 - decision_tree.py - the optimal scheduler has value: -47.71054759664841
2025-01-21 20:20:57,041 - decision_tree.py - the random scheduler has value: -99.87697400578439

2025-01-21 20:20:57,041 - mdp.py - building tree of depth 0
2025-01-21 20:20:57,069 - statistic.py - synthesis initiated, design space: 5
2025-01-21 20:20:57,078 - synthesizer_ar.py - value -99.9956 achieved after 0.15 seconds
2025-01-21 20:20:57,102 - synthesizer_ar.py - value -99.877 achieved after 0.17 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 1, family size: 5, quotient: 3292 states / 16460 actions
explored: 100 %
MDP stats: avg MDP size: 1420, iterations: 7

optimum: -99.876974
--------------------
2025-01-21 20:20:57,107 - decision_tree.py - families considered: 7
2025-01-21 20:20:57,107 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:20:57,107 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 20:20:57,107 - decision_tree.py - families model checked: 7
2025-01-21 20:20:57,108 - decision_tree.py - harmonizations attempted: 2
2025-01-21 20:20:57,108 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 20:20:57,108 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:20:57,108 - decision_tree.py - A_0=__random__
2025-01-21 20:20:57,113 - decision_tree.py - double-checking specification satisfiability:  : -99.87697400578439

2025-01-21 20:20:57,113 - mdp.py - building tree of depth 1
2025-01-21 20:20:57,251 - statistic.py - synthesis initiated, design space: 70000
2025-01-21 20:20:57,334 - synthesizer_ar.py - value -99.874 achieved after 0.4 seconds
2025-01-21 20:20:57,495 - synthesizer_ar.py - value -99.8542 achieved after 0.56 seconds
2025-01-21 20:20:57,551 - synthesizer_ar.py - value -95.1392 achieved after 0.62 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 2.82 s
number of holes: 10, family size: 70000, quotient: 3292 states / 16460 actions
explored: 200 %
MDP stats: avg MDP size: 1793, iterations: 286

optimum: -95.139217
--------------------
2025-01-21 20:21:00,075 - decision_tree.py - families considered: 286
2025-01-21 20:21:00,075 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:21:00,075 - decision_tree.py - families with schedulers preserved: 33
2025-01-21 20:21:00,075 - decision_tree.py - families model checked: 253
2025-01-21 20:21:00,075 - decision_tree.py - harmonizations attempted: 72
2025-01-21 20:21:00,075 - decision_tree.py - harmonizations succeeded: 3

2025-01-21 20:21:00,075 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:21:00,075 - decision_tree.py - V_0=gem, attacked_0=0, gem_0=0, gold_0=0, required_gem_0=0, required_gold_0=0, x_0=1, y_0=1, A_1=top, A_2=down
2025-01-21 20:21:00,076 - decision_tree.py - double-checking specification satisfiability:  : -95.13921708639764

2025-01-21 20:21:00,076 - mdp.py - building tree of depth 2
2025-01-21 20:21:00,470 - statistic.py - synthesis initiated, design space: 1e13
2025-01-21 20:21:01,389 - synthesizer_ar.py - value -94.1246 achieved after 4.46 seconds
2025-01-21 20:21:02,764 - synthesizer_ar.py - value -92.8589 achieved after 5.83 seconds
> progress 0.109%, elapsed 3 s, estimated 2737 s, iters = {MDP: 360}, opt = -92.8589
2025-01-21 20:21:04,168 - synthesizer_ar.py - value -91.6598 achieved after 7.24 seconds
> progress 0.314%, elapsed 6 s, estimated 1907 s, iters = {MDP: 698}, opt = -91.6598
2025-01-21 20:21:07,266 - synthesizer_ar.py - value -90.4542 achieved after 10.34 seconds
> progress 0.786%, elapsed 9 s, estimated 1145 s, iters = {MDP: 1006}, opt = -90.4542
> progress 1.457%, elapsed 12 s, estimated 824 s, iters = {MDP: 1238}, opt = -90.4542
> progress 1.541%, elapsed 15 s, estimated 976 s, iters = {MDP: 1424}, opt = -90.4542
> progress 4.167%, elapsed 18 s, estimated 433 s, iters = {MDP: 1746}, opt = -90.4542
> progress 4.386%, elapsed 21 s, estimated 480 s, iters = {MDP: 2092}, opt = -90.4542
> progress 4.658%, elapsed 24 s, estimated 517 s, iters = {MDP: 2453}, opt = -90.4542
> progress 4.809%, elapsed 27 s, estimated 563 s, iters = {MDP: 2681}, opt = -90.4542
> progress 4.868%, elapsed 30 s, estimated 618 s, iters = {MDP: 2990}, opt = -90.4542
> progress 5.437%, elapsed 33 s, estimated 609 s, iters = {MDP: 3173}, opt = -90.4542
> progress 5.554%, elapsed 36 s, estimated 651 s, iters = {MDP: 3291}, opt = -90.4542
> progress 5.597%, elapsed 39 s, estimated 700 s, iters = {MDP: 3409}, opt = -90.4542
> progress 5.638%, elapsed 42 s, estimated 748 s, iters = {MDP: 3512}, opt = -90.4542
2025-01-21 20:21:45,019 - synthesizer_ar.py - value -90.1493 achieved after 48.09 seconds
2025-01-21 20:21:45,459 - synthesizer_ar.py - value -68.6287 achieved after 48.53 seconds
2025-01-21 20:21:45,514 - synthesizer_ar.py - value -53.9064 achieved after 48.58 seconds
> progress 8.571%, elapsed 45 s, estimated 527 s, iters = {MDP: 3737}, opt = -53.9064
> progress 17.58%, elapsed 48 s, estimated 274 s, iters = {MDP: 4126}, opt = -53.9064
> progress 36.734%, elapsed 51 s, estimated 139 s, iters = {MDP: 4496}, opt = -53.9064
> progress 44.154%, elapsed 54 s, estimated 122 s, iters = {MDP: 4880}, opt = -53.9064
> progress 49.516%, elapsed 57 s, estimated 115 s, iters = {MDP: 5289}, opt = -53.9064
> progress 61.253%, elapsed 60 s, estimated 98 s, iters = {MDP: 5665}, opt = -53.9064
> progress 67.638%, elapsed 63 s, estimated 93 s, iters = {MDP: 6052}, opt = -53.9064
> progress 74.052%, elapsed 66 s, estimated 89 s, iters = {MDP: 6434}, opt = -53.9064
> progress 83.979%, elapsed 69 s, estimated 82 s, iters = {MDP: 6843}, opt = -53.9064
> progress 92.157%, elapsed 72 s, estimated 78 s, iters = {MDP: 7202}, opt = -53.9064
> progress 95.218%, elapsed 75 s, estimated 79 s, iters = {MDP: 7613}, opt = -53.9064
> progress 97.422%, elapsed 78 s, estimated 80 s, iters = {MDP: 7976}, opt = -53.9064
> progress 102.215%, elapsed 81 s, estimated 79 s, iters = {MDP: 8377}, opt = -53.9064
> progress 108.163%, elapsed 84 s, estimated 77 s, iters = {MDP: 8725}, opt = -53.9064
2025-01-21 20:22:26,191 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 85.72 s
number of holes: 28, family size: 1e13, quotient: 3292 states / 16460 actions
explored: 113 %
MDP stats: avg MDP size: 1658, iterations: 8871

optimum: -53.906396
--------------------
2025-01-21 20:22:26,192 - decision_tree.py - families considered: 8871
2025-01-21 20:22:26,192 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:22:26,192 - decision_tree.py - families with schedulers preserved: 1738
2025-01-21 20:22:26,192 - decision_tree.py - families model checked: 7133
2025-01-21 20:22:26,192 - decision_tree.py - harmonizations attempted: 1581
2025-01-21 20:22:26,192 - decision_tree.py - harmonizations succeeded: 4

2025-01-21 20:22:26,192 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:22:26,192 - decision_tree.py - V_0=gem, attacked_0=0, gem_0=0, gold_0=0, required_gem_0=0, required_gold_0=0, x_0=1, y_0=1, V_1=y, attacked_1=0, gem_1=0, gold_1=0, required_gem_1=0, required_gold_1=0, x_1=1, y_1=4, A_2=top, A_3=right, V_4=y, attacked_4=0, gem_4=0, gold_4=0, required_gem_4=0, required_gold_4=0, x_4=1, y_4=1, A_5=left, A_6=down
2025-01-21 20:22:26,193 - decision_tree.py - double-checking specification satisfiability:  : -53.90639575082535

2025-01-21 20:22:26,193 - mdp.py - building tree of depth 3
2025-01-21 20:22:27,051 - statistic.py - synthesis initiated, design space: 1e29
2025-01-21 20:22:27,124 - synthesizer_ar.py - value -47.7105 achieved after 90.19 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.46 s
number of holes: 64, family size: 1e29, quotient: 3292 states / 16460 actions
explored: 100 %
MDP stats: avg MDP size: 3032, iterations: 36

optimum: -47.710539
--------------------
2025-01-21 20:22:27,513 - decision_tree.py - families considered: 36
2025-01-21 20:22:27,513 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:22:27,513 - decision_tree.py - families with schedulers preserved: 11
2025-01-21 20:22:27,513 - decision_tree.py - families model checked: 25
2025-01-21 20:22:27,513 - decision_tree.py - harmonizations attempted: 1
2025-01-21 20:22:27,513 - decision_tree.py - harmonizations succeeded: 0

2025-01-21 20:22:27,513 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:22:27,513 - decision_tree.py - V_0=gem, attacked_0=0, gem_0=0, gold_0=0, required_gem_0=0, required_gold_0=0, x_0=1, y_0=1, V_1=y, attacked_1=0, gem_1=0, gold_1=0, required_gem_1=0, required_gold_1=0, x_1=1, y_1=4, V_2=required_gold, attacked_2=0, gem_2=0, gold_2=0, required_gem_2=0, required_gold_2=0, x_2=1, y_2=1, A_3=down, A_4=top, V_5=x, attacked_5=0, gem_5=0, gold_5=0, required_gem_5=0, required_gold_5=4, x_5=4, y_5=1, A_6=right, A_7=down, V_8=y, attacked_8=0, gem_8=0, gold_8=0, required_gem_8=0, required_gold_8=0, x_8=1, y_8=1, V_9=required_gold, attacked_9=0, gem_9=0, gold_9=0, required_gem_9=0, required_gold_9=1, x_9=1, y_9=1, A_10=left, A_11=left, V_12=gem, attacked_12=0, gem_12=0, gold_12=0, required_gem_12=0, required_gold_12=0, x_12=1, y_12=1, A_13=__random__, A_14=down
2025-01-21 20:22:27,515 - decision_tree.py - double-checking specification satisfiability:  : -47.71053916989508
2025-01-21 20:22:27,515 - decision_tree.py - the optimal scheduler has value: -47.71054759664841
2025-01-21 20:22:27,515 - decision_tree.py - the random scheduler has value: -99.87697400578439
2025-01-21 20:22:27,516 - decision_tree.py - synthesized tree of depth 3 with 5 decision nodes
2025-01-21 20:22:27,516 - decision_tree.py - the synthesized tree has value -47.71053916989508
2025-01-21 20:22:27,516 - decision_tree.py - the synthesized tree has relative value: 1.0000001615359517
2025-01-21 20:22:27,516 - decision_tree.py - printing the synthesized tree below:
if gem<=0:
  if y<=4:
    if required_gold<=0:
      down
    else:
      top
  else:
    if x<=4:
      right
    else:
      down
else:
  if y<=1:
    left
  else:
    down

2025-01-21 20:22:27,517 - decision_tree.py - exported decision tree to logs/01-21-all/7/qcomp-resource-gathering-5/tree.dot
2025-01-21 20:22:27,565 - decision_tree.py - exported decision tree visualization to logs/01-21-all/7/qcomp-resource-gathering-5/tree.png
2025-01-21 20:22:27,565 - decision_tree.py - synthesis finished after 90.63 seconds

ColoringSmt = 0.818 s (0.9 %)
ColoringSmt:: create choice colors = 0.188 s (0.2 %)
ColoringSmt:: create harmonizing variants = 0.627 s (0.7 %)
areChoicesConsistent = 0.153 s (0.2 %)
areChoicesConsistent::1 is scheduler consistent? = 0.08 s (0.1 %)
areChoicesConsistent::2 better unsat core = 0.044 s (0.0 %)
areChoicesConsistent::3 unsat core analysis = 0.026 s (0.0 %)
check = 0.13 s (0.1 %)
loadUnsatCore = 0.0 s (0.0 %)
selectCompatibleChoices = 0.162 s (0.2 %)
selectCompatibleChoices::1 is family sat = 0.095 s (0.1 %)
selectCompatibleChoices::2 state exploration = 0.066 s (0.1 %)
