2025-01-21 18:30:51,008 - cli.py - This is Paynt version 0.1.0.
2025-01-21 18:30:51,008 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/omdt/frozenlake_4x4/model-random.drn ...
2025-01-21 18:30:51,008 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 18:30:51,009 - sketch.py - assuming sketch in DRN format...
2025-01-21 18:30:51,009 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/omdt/frozenlake_4x4/discounted.props ...
2025-01-21 18:30:51,010 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 18:30:51,010 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/omdt/frozenlake_4x4/state-valuations.json, adding to the model...
2025-01-21 18:30:51,010 - sketch.py - sketch parsing OK
2025-01-21 18:30:51,010 - sketch.py - constructed explicit quotient having 16 states and 80 choices
2025-01-21 18:30:51,010 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 18:30:51,010 - mdp.py - MDP has 11/16 relevant states
2025-01-21 18:30:51,010 - mdp.py - MDP has 5 actions
2025-01-21 18:30:51,011 - mdp.py - found the following 2 variables: ['X:[0..3]', 'Y:[0..3]']
2025-01-21 18:30:51,014 - decision_tree.py - the optimal scheduler has value: 0.5420211536822956
2025-01-21 18:30:51,014 - decision_tree.py - the random scheduler has value: 0.012356099192929595

2025-01-21 18:30:51,014 - mdp.py - building tree of depth 0
2025-01-21 18:30:51,017 - statistic.py - synthesis initiated, design space: 5
2025-01-21 18:30:51,020 - synthesizer_ar.py - value 0.0 achieved after 0.01 seconds
2025-01-21 18:30:51,022 - synthesizer_ar.py - value 0.0448 achieved after 0.01 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 5, quotient: 16 states / 80 actions
explored: 100 %
MDP stats: avg MDP size: 13, iterations: 7

optimum: 0.044849
--------------------
2025-01-21 18:30:51,023 - decision_tree.py - families considered: 7
2025-01-21 18:30:51,023 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:30:51,023 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 18:30:51,023 - decision_tree.py - families model checked: 7
2025-01-21 18:30:51,023 - decision_tree.py - harmonizations attempted: 2
2025-01-21 18:30:51,023 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 18:30:51,023 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:30:51,023 - decision_tree.py - A_0=(Down)
2025-01-21 18:30:51,023 - decision_tree.py - double-checking specification satisfiability:  : 0.04484860150108872

2025-01-21 18:30:51,023 - mdp.py - building tree of depth 1
2025-01-21 18:30:51,029 - statistic.py - synthesis initiated, design space: 450
2025-01-21 18:30:51,032 - synthesizer_ar.py - value 0.0932 achieved after 0.02 seconds
2025-01-21 18:30:51,085 - synthesizer_ar.py - value 0.1104 achieved after 0.08 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.14 s
number of holes: 5, family size: 450, quotient: 16 states / 80 actions
explored: 200 %
MDP stats: avg MDP size: 14, iterations: 159

optimum: 0.110398
--------------------
2025-01-21 18:30:51,168 - decision_tree.py - families considered: 159
2025-01-21 18:30:51,168 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:30:51,168 - decision_tree.py - families with schedulers preserved: 20
2025-01-21 18:30:51,168 - decision_tree.py - families model checked: 139
2025-01-21 18:30:51,168 - decision_tree.py - harmonizations attempted: 42
2025-01-21 18:30:51,168 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 18:30:51,168 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:30:51,168 - decision_tree.py - V_0=Y, X_0=0, Y_0=1, A_1=(Left), A_2=(Down)
2025-01-21 18:30:51,168 - decision_tree.py - double-checking specification satisfiability:  : 0.11039774568631427

2025-01-21 18:30:51,168 - mdp.py - building tree of depth 2
2025-01-21 18:30:51,174 - statistic.py - synthesis initiated, design space: 1e6
2025-01-21 18:30:51,189 - synthesizer_ar.py - value 0.1417 achieved after 0.18 seconds
2025-01-21 18:30:51,287 - synthesizer_ar.py - value 0.2558 achieved after 0.28 seconds
2025-01-21 18:30:51,432 - synthesizer_ar.py - value 0.3652 achieved after 0.42 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.28 s
number of holes: 13, family size: 1e6, quotient: 16 states / 80 actions
explored: 116 %
MDP stats: avg MDP size: 15, iterations: 207

optimum: 0.365162
--------------------
2025-01-21 18:30:51,451 - decision_tree.py - families considered: 207
2025-01-21 18:30:51,452 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:30:51,452 - decision_tree.py - families with schedulers preserved: 64
2025-01-21 18:30:51,452 - decision_tree.py - families model checked: 143
2025-01-21 18:30:51,452 - decision_tree.py - harmonizations attempted: 17
2025-01-21 18:30:51,452 - decision_tree.py - harmonizations succeeded: 0

2025-01-21 18:30:51,452 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:30:51,452 - decision_tree.py - V_0=X, X_0=0, Y_0=0, V_1=Y, X_1=0, Y_1=1, A_2=(Left), A_3=(Up), V_4=Y, X_4=0, Y_4=2, A_5=(Down), A_6=(Right)
2025-01-21 18:30:51,452 - decision_tree.py - double-checking specification satisfiability:  : 0.3651615039430263

2025-01-21 18:30:51,452 - mdp.py - building tree of depth 3
2025-01-21 18:30:51,458 - statistic.py - synthesis initiated, design space: 1e14
2025-01-21 18:30:51,486 - synthesizer_ar.py - value 0.4447 achieved after 0.48 seconds
2025-01-21 18:30:51,564 - synthesizer_ar.py - value 0.5201 achieved after 0.56 seconds
> progress 0.671%, elapsed 3 s, estimated 447 s, iters = {MDP: 1467}, opt = 0.5201
> progress 2.717%, elapsed 6 s, estimated 220 s, iters = {MDP: 2889}, opt = 0.5201
> progress 6.879%, elapsed 9 s, estimated 130 s, iters = {MDP: 4230}, opt = 0.5201
> progress 11.871%, elapsed 12 s, estimated 101 s, iters = {MDP: 5569}, opt = 0.5201
> progress 13.368%, elapsed 15 s, estimated 112 s, iters = {MDP: 6902}, opt = 0.5201
> progress 15.34%, elapsed 18 s, estimated 117 s, iters = {MDP: 8332}, opt = 0.5201
> progress 20.987%, elapsed 21 s, estimated 100 s, iters = {MDP: 9669}, opt = 0.5201
> progress 21.789%, elapsed 24 s, estimated 110 s, iters = {MDP: 11002}, opt = 0.5201
> progress 22.881%, elapsed 27 s, estimated 118 s, iters = {MDP: 12372}, opt = 0.5201
> progress 23.109%, elapsed 30 s, estimated 129 s, iters = {MDP: 13753}, opt = 0.5201
> progress 24.364%, elapsed 33 s, estimated 135 s, iters = {MDP: 15106}, opt = 0.5201
> progress 30.266%, elapsed 36 s, estimated 119 s, iters = {MDP: 16487}, opt = 0.5201
> progress 33.813%, elapsed 39 s, estimated 115 s, iters = {MDP: 17800}, opt = 0.5201
> progress 34.307%, elapsed 42 s, estimated 122 s, iters = {MDP: 19099}, opt = 0.5201
> progress 35.765%, elapsed 45 s, estimated 125 s, iters = {MDP: 20411}, opt = 0.5201
> progress 36.059%, elapsed 48 s, estimated 133 s, iters = {MDP: 21694}, opt = 0.5201
> progress 38.332%, elapsed 51 s, estimated 133 s, iters = {MDP: 23027}, opt = 0.5201
> progress 38.722%, elapsed 54 s, estimated 139 s, iters = {MDP: 24373}, opt = 0.5201
> progress 40.277%, elapsed 57 s, estimated 141 s, iters = {MDP: 25669}, opt = 0.5201
> progress 41.144%, elapsed 60 s, estimated 145 s, iters = {MDP: 27015}, opt = 0.5201
> progress 42.281%, elapsed 63 s, estimated 149 s, iters = {MDP: 28296}, opt = 0.5201
> progress 44.997%, elapsed 66 s, estimated 146 s, iters = {MDP: 29562}, opt = 0.5201
> progress 46.02%, elapsed 69 s, estimated 150 s, iters = {MDP: 30912}, opt = 0.5201
> progress 47.264%, elapsed 72 s, estimated 152 s, iters = {MDP: 32273}, opt = 0.5201
> progress 47.389%, elapsed 75 s, estimated 158 s, iters = {MDP: 33702}, opt = 0.5201
> progress 48.148%, elapsed 78 s, estimated 162 s, iters = {MDP: 35006}, opt = 0.5201
> progress 48.845%, elapsed 81 s, estimated 165 s, iters = {MDP: 36300}, opt = 0.5201
> progress 49.121%, elapsed 84 s, estimated 171 s, iters = {MDP: 37642}, opt = 0.5201
> progress 49.191%, elapsed 87 s, estimated 176 s, iters = {MDP: 38989}, opt = 0.5201
> progress 49.302%, elapsed 90 s, estimated 182 s, iters = {MDP: 40378}, opt = 0.5201
> progress 50.402%, elapsed 93 s, estimated 184 s, iters = {MDP: 41743}, opt = 0.5201
> progress 51.718%, elapsed 96 s, estimated 185 s, iters = {MDP: 43081}, opt = 0.5201
> progress 52.428%, elapsed 99 s, estimated 188 s, iters = {MDP: 44476}, opt = 0.5201
> progress 52.566%, elapsed 102 s, estimated 194 s, iters = {MDP: 45833}, opt = 0.5201
> progress 53.061%, elapsed 105 s, estimated 198 s, iters = {MDP: 47222}, opt = 0.5201
> progress 55.0%, elapsed 108 s, estimated 196 s, iters = {MDP: 48546}, opt = 0.5201
> progress 57.088%, elapsed 111 s, estimated 194 s, iters = {MDP: 49889}, opt = 0.5201
> progress 58.315%, elapsed 114 s, estimated 195 s, iters = {MDP: 51202}, opt = 0.5201
> progress 58.901%, elapsed 117 s, estimated 198 s, iters = {MDP: 52551}, opt = 0.5201
2025-01-21 18:32:51,459 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 120.0 s
number of holes: 29, family size: 1e14, quotient: 16 states / 80 actions
explored: 59 %
MDP stats: avg MDP size: 15, iterations: 53883

optimum: 0.520116
--------------------
2025-01-21 18:32:51,459 - decision_tree.py - families considered: 53883
2025-01-21 18:32:51,459 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:32:51,459 - decision_tree.py - families with schedulers preserved: 21664
2025-01-21 18:32:51,459 - decision_tree.py - families model checked: 32219
2025-01-21 18:32:51,459 - decision_tree.py - harmonizations attempted: 331
2025-01-21 18:32:51,459 - decision_tree.py - harmonizations succeeded: 0

2025-01-21 18:32:51,459 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:32:51,459 - decision_tree.py - V_0=X, X_0=0, Y_0=0, V_1=Y, X_1=0, Y_1=1, V_2=Y, X_2=0, Y_2=1, A_3=(Left), A_4=(Left), V_5=X, X_5=0, Y_5=0, A_6=(Up), A_7=(Down), V_8=Y, X_8=0, Y_8=2, V_9=X, X_9=1, Y_9=0, A_10=(Down), A_11=(Left), V_12=X, X_12=1, Y_12=0, A_13=(Right), A_14=(Down)
2025-01-21 18:32:51,460 - decision_tree.py - double-checking specification satisfiability:  : 0.5201162480246683

2025-01-21 18:32:51,460 - mdp.py - building tree of depth 4
2025-01-21 18:32:51,469 - statistic.py - synthesis initiated, design space: 1e30
2025-01-21 18:32:51,476 - synthesizer_ar.py - value 0.542 achieved after 120.47 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 61, family size: 1e30, quotient: 16 states / 80 actions
explored: 100 %
MDP stats: avg MDP size: 16, iterations: 2

optimum: 0.542021
--------------------
2025-01-21 18:32:51,478 - decision_tree.py - families considered: 2
2025-01-21 18:32:51,478 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:32:51,478 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 18:32:51,478 - decision_tree.py - families model checked: 2
2025-01-21 18:32:51,478 - decision_tree.py - harmonizations attempted: 0
2025-01-21 18:32:51,478 - decision_tree.py - harmonizations succeeded: 0

2025-01-21 18:32:51,478 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:32:51,478 - decision_tree.py - V_0=X, X_0=0, Y_0=0, V_1=Y, X_1=0, Y_1=1, V_2=Y, X_2=0, Y_2=1, V_3=X, X_3=0, Y_3=0, A_4=(Left), A_5=(Right), V_6=X, X_6=0, Y_6=0, A_7=(Down), A_8=(Right), V_9=X, X_9=0, Y_9=0, V_10=Y, X_10=0, Y_10=2, A_11=(Up), A_12=(Down), V_13=X, X_13=0, Y_13=0, A_14=(Down), A_15=(Down), V_16=Y, X_16=0, Y_16=2, V_17=X, X_17=1, Y_17=0, V_18=Y, X_18=0, Y_18=1, A_19=(Up), A_20=(Down), V_21=Y, X_21=0, Y_21=0, A_22=(Up), A_23=(Left), V_24=X, X_24=1, Y_24=0, V_25=X, X_25=1, Y_25=0, A_26=(Right), A_27=(Down), V_28=X, X_28=2, Y_28=0, A_29=(Down), A_30=(Down)
2025-01-21 18:32:51,479 - decision_tree.py - double-checking specification satisfiability:  : 0.5420210675142317
2025-01-21 18:32:51,479 - decision_tree.py - the optimal scheduler has value: 0.5420211536822956
2025-01-21 18:32:51,479 - decision_tree.py - the random scheduler has value: 0.012356099192929595
2025-01-21 18:32:51,479 - decision_tree.py - synthesized tree of depth 4 with 7 decision nodes
2025-01-21 18:32:51,479 - decision_tree.py - the synthesized tree has value 0.5420210675142317
2025-01-21 18:32:51,479 - decision_tree.py - the synthesized tree has relative value: 0.9999998373159354
2025-01-21 18:32:51,479 - decision_tree.py - printing the synthesized tree below:
if X<=0:
  if Y<=1:
    (Left)
  else:
    (Up)
else:
  if Y<=2:
    if X<=1:
      if Y<=1:
        (Up)
      else:
        (Down)
    else:
      if Y<=0:
        (Up)
      else:
        (Left)
  else:
    if X<=1:
      (Right)
    else:
      (Down)

2025-01-21 18:32:51,480 - decision_tree.py - exported decision tree to logs/01-21-all/5/omdt-frozenlake_4x4/tree.dot
2025-01-21 18:32:51,532 - decision_tree.py - exported decision tree visualization to logs/01-21-all/5/omdt-frozenlake_4x4/tree.png
2025-01-21 18:32:51,532 - decision_tree.py - synthesis finished after 120.52 seconds

ColoringSmt = 0.002 s (0.0 %)
ColoringSmt:: create choice colors = 0.0 s (0.0 %)
ColoringSmt:: create harmonizing variants = 0.001 s (0.0 %)
areChoicesConsistent = 0.002 s (0.0 %)
areChoicesConsistent::1 is scheduler consistent? = 0.002 s (0.0 %)
check = 0.004 s (0.0 %)
selectCompatibleChoices = 0.005 s (0.0 %)
selectCompatibleChoices::1 is family sat = 0.005 s (0.0 %)
selectCompatibleChoices::2 state exploration = 0.0 s (0.0 %)
