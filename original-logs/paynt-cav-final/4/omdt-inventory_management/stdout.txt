2025-01-21 17:45:15,848 - cli.py - This is Paynt version 0.1.0.
2025-01-21 17:45:15,848 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/omdt/inventory_management/model-random.drn ...
2025-01-21 17:45:15,848 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 17:45:16,140 - sketch.py - assuming sketch in DRN format...
2025-01-21 17:45:16,411 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/omdt/inventory_management/discounted.props ...
2025-01-21 17:45:16,411 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 17:45:16,411 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/omdt/inventory_management/state-valuations.json, adding to the model...
2025-01-21 17:45:16,412 - sketch.py - sketch parsing OK
2025-01-21 17:45:16,453 - sketch.py - constructed explicit quotient having 101 states and 10201 choices
2025-01-21 17:45:16,453 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 17:45:16,453 - mdp.py - MDP has 101/101 relevant states
2025-01-21 17:45:16,578 - mdp.py - MDP has 101 actions
2025-01-21 17:45:16,579 - mdp.py - found the following 1 variables: ['inventory:[0..100]']
2025-01-21 17:45:16,921 - decision_tree.py - the optimal scheduler has value: 967.8226692269506
2025-01-21 17:45:16,925 - decision_tree.py - the random scheduler has value: -960.240971558256

2025-01-21 17:45:16,925 - mdp.py - building tree of depth 0
2025-01-21 17:45:16,937 - statistic.py - synthesis initiated, design space: 101
2025-01-21 17:45:17,299 - synthesizer_ar.py - value 927.6808 achieved after 1.45 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.03 s
number of holes: 1, family size: 101, quotient: 101 states / 10201 actions
explored: 100 %
MDP stats: avg MDP size: 101, iterations: 7

optimum: 927.680823
--------------------
2025-01-21 17:45:17,964 - decision_tree.py - families considered: 7
2025-01-21 17:45:17,964 - decision_tree.py - families skipped by construction: 0
2025-01-21 17:45:17,964 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 17:45:17,964 - decision_tree.py - families model checked: 7
2025-01-21 17:45:17,964 - decision_tree.py - harmonizations attempted: 2
2025-01-21 17:45:17,964 - decision_tree.py - harmonizations succeeded: 1

2025-01-21 17:45:17,964 - decision_tree.py - printing synthesized assignment below:
2025-01-21 17:45:17,964 - decision_tree.py - A_0=(Buy_11)
2025-01-21 17:45:17,968 - decision_tree.py - double-checking specification satisfiability:  : 927.6808229068353

2025-01-21 17:45:17,968 - mdp.py - building tree of depth 1
2025-01-21 17:45:17,991 - statistic.py - synthesis initiated, design space: 1e6
2025-01-21 17:45:18,354 - synthesizer_ar.py - value 948.9069 achieved after 2.51 seconds
2025-01-21 17:45:18,357 - synthesizer_ar.py - value 951.3556 achieved after 2.51 seconds
2025-01-21 17:45:18,390 - synthesizer_ar.py - value 952.0958 achieved after 2.54 seconds
2025-01-21 17:45:18,766 - synthesizer_ar.py - value 955.2716 achieved after 2.92 seconds
> progress 100.99%, elapsed 3 s, estimated 3 s, iters = {MDP: 21}, opt = 955.2716
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 4.0 s
number of holes: 4, family size: 1e6, quotient: 101 states / 10201 actions
explored: 200 %
MDP stats: avg MDP size: 101, iterations: 22

optimum: 955.271598
--------------------
2025-01-21 17:45:21,988 - decision_tree.py - families considered: 22
2025-01-21 17:45:21,988 - decision_tree.py - families skipped by construction: 0
2025-01-21 17:45:21,988 - decision_tree.py - families with schedulers preserved: 3
2025-01-21 17:45:21,988 - decision_tree.py - families model checked: 19
2025-01-21 17:45:21,988 - decision_tree.py - harmonizations attempted: 4
2025-01-21 17:45:21,988 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 17:45:21,988 - decision_tree.py - printing synthesized assignment below:
2025-01-21 17:45:21,988 - decision_tree.py - V_0=inventory, inventory_0=1, A_1=(Buy_12), A_2=(Buy_8)
2025-01-21 17:45:21,992 - decision_tree.py - double-checking specification satisfiability:  : 955.2715976427129

2025-01-21 17:45:21,992 - mdp.py - building tree of depth 2
2025-01-21 17:45:22,036 - statistic.py - synthesis initiated, design space: 1e14
2025-01-21 17:45:22,819 - synthesizer_ar.py - value 963.9164 achieved after 6.97 seconds
2025-01-21 17:45:22,841 - synthesizer_ar.py - value 964.2478 achieved after 6.99 seconds
> progress 0.038%, elapsed 3 s, estimated 8699 s (2 hours), iters = {MDP: 17}, opt = 964.2478
2025-01-21 17:45:26,104 - synthesizer_ar.py - value 964.8321 achieved after 10.26 seconds
2025-01-21 17:45:26,122 - synthesizer_ar.py - value 965.5214 achieved after 10.27 seconds
> progress 0.97%, elapsed 6 s, estimated 677 s, iters = {MDP: 32}, opt = 965.5214
> progress 1.932%, elapsed 9 s, estimated 511 s, iters = {MDP: 49}, opt = 965.5214
> progress 97.95%, elapsed 13 s, estimated 13 s, iters = {MDP: 64}, opt = 965.5214
> progress 98.9%, elapsed 16 s, estimated 16 s, iters = {MDP: 77}, opt = 965.5214
2025-01-21 17:45:41,401 - synthesizer_ar.py - value 965.785 achieved after 25.55 seconds
2025-01-21 17:45:41,421 - synthesizer_ar.py - value 966.0764 achieved after 25.57 seconds
> progress 98.91%, elapsed 19 s, estimated 19 s, iters = {MDP: 92}, opt = 966.0764
> progress 100.84%, elapsed 23 s, estimated 22 s, iters = {MDP: 109}, opt = 966.0764
> progress 100.84%, elapsed 26 s, estimated 26 s, iters = {MDP: 120}, opt = 966.0764
> progress 100.84%, elapsed 29 s, estimated 29 s, iters = {MDP: 135}, opt = 966.0764
> progress 100.84%, elapsed 32 s, estimated 32 s, iters = {MDP: 152}, opt = 966.0764
> progress 100.841%, elapsed 36 s, estimated 35 s, iters = {MDP: 168}, opt = 966.0764
> progress 100.879%, elapsed 39 s, estimated 38 s, iters = {MDP: 181}, opt = 966.0764
> progress 100.879%, elapsed 42 s, estimated 41 s, iters = {MDP: 192}, opt = 966.0764
> progress 100.879%, elapsed 45 s, estimated 45 s, iters = {MDP: 203}, opt = 966.0764
> progress 100.88%, elapsed 48 s, estimated 48 s, iters = {MDP: 217}, opt = 966.0764
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 52.17 s
number of holes: 10, family size: 1e14, quotient: 101 states / 10201 actions
explored: 101 %
MDP stats: avg MDP size: 101, iterations: 232

optimum: 966.076354
--------------------
2025-01-21 17:46:14,208 - decision_tree.py - families considered: 232
2025-01-21 17:46:14,208 - decision_tree.py - families skipped by construction: 0
2025-01-21 17:46:14,208 - decision_tree.py - families with schedulers preserved: 59
2025-01-21 17:46:14,209 - decision_tree.py - families model checked: 173
2025-01-21 17:46:14,209 - decision_tree.py - harmonizations attempted: 28
2025-01-21 17:46:14,209 - decision_tree.py - harmonizations succeeded: 0

2025-01-21 17:46:14,209 - decision_tree.py - printing synthesized assignment below:
2025-01-21 17:46:14,209 - decision_tree.py - V_0=inventory, inventory_0=2, V_1=inventory, inventory_1=0, A_2=(Buy_12), A_3=(Buy_10), V_4=inventory, inventory_4=4, A_5=(Buy_8), A_6=(Buy_5)
2025-01-21 17:46:14,213 - decision_tree.py - double-checking specification satisfiability:  : 966.0763537849454

2025-01-21 17:46:14,213 - mdp.py - building tree of depth 3
2025-01-21 17:46:14,290 - statistic.py - synthesis initiated, design space: 1e30
2025-01-21 17:46:15,129 - synthesizer_ar.py - value 967.2347 achieved after 59.28 seconds
2025-01-21 17:46:15,168 - synthesizer_ar.py - value 967.2479 achieved after 59.32 seconds
2025-01-21 17:46:16,296 - synthesizer_ar.py - value 967.3612 achieved after 60.45 seconds
2025-01-21 17:46:16,330 - synthesizer_ar.py - value 967.3742 achieved after 60.48 seconds
> progress 0.0%, elapsed 3 s, estimated 3430454 s (39 days), iters = {MDP: 17}, opt = 967.3742
2025-01-21 17:46:17,507 - synthesizer_ar.py - value 967.505 achieved after 61.66 seconds
2025-01-21 17:46:17,540 - synthesizer_ar.py - value 967.5474 achieved after 61.69 seconds
2025-01-21 17:46:18,693 - synthesizer_ar.py - value 967.6131 achieved after 62.84 seconds
> progress 0.007%, elapsed 6 s, estimated 86775 s (24 hours), iters = {MDP: 38}, opt = 967.6131
> progress 0.788%, elapsed 9 s, estimated 1250 s, iters = {MDP: 52}, opt = 967.6131
> progress 0.789%, elapsed 13 s, estimated 1664 s, iters = {MDP: 65}, opt = 967.6131
> progress 0.813%, elapsed 16 s, estimated 1995 s, iters = {MDP: 82}, opt = 967.6131
> progress 0.813%, elapsed 19 s, estimated 2397 s, iters = {MDP: 95}, opt = 967.6131
> progress 0.853%, elapsed 22 s, estimated 2644 s, iters = {MDP: 110}, opt = 967.6131
> progress 0.853%, elapsed 25 s, estimated 2999 s, iters = {MDP: 121}, opt = 967.6131
> progress 0.854%, elapsed 28 s, estimated 3348 s, iters = {MDP: 135}, opt = 967.6131
> progress 0.854%, elapsed 31 s, estimated 3705 s, iters = {MDP: 150}, opt = 967.6131
> progress 0.854%, elapsed 34 s, estimated 4091 s, iters = {MDP: 163}, opt = 967.6131
> progress 0.854%, elapsed 38 s, estimated 4487 s, iters = {MDP: 178}, opt = 967.6131
> progress 0.854%, elapsed 41 s, estimated 4846 s, iters = {MDP: 193}, opt = 967.6131
> progress 0.854%, elapsed 44 s, estimated 5229 s, iters = {MDP: 207}, opt = 967.6131
> progress 0.856%, elapsed 47 s, estimated 5591 s, iters = {MDP: 217}, opt = 967.6131
> progress 0.856%, elapsed 50 s, estimated 5948 s, iters = {MDP: 234}, opt = 967.6131
> progress 0.882%, elapsed 54 s, estimated 6152 s, iters = {MDP: 246}, opt = 967.6131
> progress 0.907%, elapsed 57 s, estimated 6318 s, iters = {MDP: 263}, opt = 967.6131
> progress 0.909%, elapsed 60 s, estimated 6669 s, iters = {MDP: 277}, opt = 967.6131
> progress 0.909%, elapsed 63 s, estimated 7002 s, iters = {MDP: 289}, opt = 967.6131
> progress 0.91%, elapsed 66 s, estimated 7325 s (2 hours), iters = {MDP: 303}, opt = 967.6131
> progress 0.91%, elapsed 69 s, estimated 7657 s (2 hours), iters = {MDP: 317}, opt = 967.6131
> progress 0.91%, elapsed 73 s, estimated 8027 s (2 hours), iters = {MDP: 331}, opt = 967.6131
> progress 0.91%, elapsed 76 s, estimated 8395 s (2 hours), iters = {MDP: 346}, opt = 967.6131
> progress 0.91%, elapsed 79 s, estimated 8723 s (2 hours), iters = {MDP: 360}, opt = 967.6131
> progress 0.918%, elapsed 82 s, estimated 8982 s (2 hours), iters = {MDP: 374}, opt = 967.6131
> progress 0.918%, elapsed 85 s, estimated 9339 s (2 hours), iters = {MDP: 388}, opt = 967.6131
> progress 0.918%, elapsed 88 s, estimated 9673 s (2 hours), iters = {MDP: 403}, opt = 967.6131
> progress 0.919%, elapsed 92 s, estimated 10028 s (2 hours), iters = {MDP: 415}, opt = 967.6131
> progress 0.919%, elapsed 95 s, estimated 10354 s (2 hours), iters = {MDP: 431}, opt = 967.6131
> progress 0.919%, elapsed 98 s, estimated 10683 s (2 hours), iters = {MDP: 446}, opt = 967.6131
> progress 0.919%, elapsed 101 s, estimated 11042 s (3 hours), iters = {MDP: 461}, opt = 967.6131
> progress 0.919%, elapsed 104 s, estimated 11406 s (3 hours), iters = {MDP: 477}, opt = 967.6131
> progress 1.821%, elapsed 107 s, estimated 5926 s, iters = {MDP: 489}, opt = 967.6131
> progress 2.636%, elapsed 111 s, estimated 4221 s, iters = {MDP: 503}, opt = 967.6131
> progress 2.644%, elapsed 114 s, estimated 4323 s, iters = {MDP: 517}, opt = 967.6131
> progress 2.652%, elapsed 117 s, estimated 4425 s, iters = {MDP: 532}, opt = 967.6131
> progress 2.669%, elapsed 120 s, estimated 4511 s, iters = {MDP: 546}, opt = 967.6131
> progress 2.669%, elapsed 123 s, estimated 4633 s, iters = {MDP: 558}, opt = 967.6131
> progress 2.722%, elapsed 126 s, estimated 4653 s, iters = {MDP: 572}, opt = 967.6131
> progress 3.537%, elapsed 129 s, estimated 3667 s, iters = {MDP: 587}, opt = 967.6131
> progress 3.537%, elapsed 133 s, estimated 3761 s, iters = {MDP: 601}, opt = 967.6131
> progress 3.538%, elapsed 136 s, estimated 3845 s, iters = {MDP: 614}, opt = 967.6131
> progress 3.538%, elapsed 139 s, estimated 3939 s, iters = {MDP: 627}, opt = 967.6131
> progress 3.57%, elapsed 142 s, estimated 3989 s, iters = {MDP: 642}, opt = 967.6131
> progress 3.57%, elapsed 145 s, estimated 4081 s, iters = {MDP: 657}, opt = 967.6131
> progress 3.571%, elapsed 149 s, estimated 4175 s, iters = {MDP: 672}, opt = 967.6131
2025-01-21 17:48:44,478 - synthesizer.py - time limit reached, aborting...
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 150.19 s
number of holes: 22, family size: 1e30, quotient: 101 states / 10201 actions
explored: 3 %
MDP stats: avg MDP size: 101, iterations: 676

optimum: 967.613055
--------------------
2025-01-21 17:48:44,478 - decision_tree.py - families considered: 676
2025-01-21 17:48:44,478 - decision_tree.py - families skipped by construction: 0
2025-01-21 17:48:44,478 - decision_tree.py - families with schedulers preserved: 268
2025-01-21 17:48:44,478 - decision_tree.py - families model checked: 408
2025-01-21 17:48:44,478 - decision_tree.py - harmonizations attempted: 6
2025-01-21 17:48:44,478 - decision_tree.py - harmonizations succeeded: 0

2025-01-21 17:48:44,478 - decision_tree.py - printing synthesized assignment below:
2025-01-21 17:48:44,478 - decision_tree.py - V_0=inventory, inventory_0=2, V_1=inventory, inventory_1=0, V_2=inventory, inventory_2=0, A_3=(Buy_12), A_4=(Buy_1), V_5=inventory, inventory_5=1, A_6=(Buy_11), A_7=(Buy_9), V_8=inventory, inventory_8=4, V_9=inventory, inventory_9=3, A_10=(Buy_8), A_11=(Buy_7), V_12=inventory, inventory_12=5, A_13=(Buy_6), A_14=(Buy_4)
2025-01-21 17:48:44,482 - decision_tree.py - double-checking specification satisfiability:  : 967.6130551320725
2025-01-21 17:48:44,482 - decision_tree.py - the optimal scheduler has value: 967.8226692269506
2025-01-21 17:48:44,482 - decision_tree.py - the random scheduler has value: -960.240971558256
2025-01-21 17:48:44,482 - decision_tree.py - synthesized tree of depth 3 with 6 decision nodes
2025-01-21 17:48:44,482 - decision_tree.py - the synthesized tree has value 967.6130551320725
2025-01-21 17:48:44,482 - decision_tree.py - the synthesized tree has relative value: 0.9998912825850537
2025-01-21 17:48:44,482 - decision_tree.py - printing the synthesized tree below:
if inventory<=2:
  if inventory<=0:
    (Buy_12)
  else:
    if inventory<=1:
      (Buy_11)
    else:
      (Buy_9)
else:
  if inventory<=4:
    if inventory<=3:
      (Buy_8)
    else:
      (Buy_7)
  else:
    if inventory<=5:
      (Buy_6)
    else:
      (Buy_4)

2025-01-21 17:48:44,483 - decision_tree.py - exported decision tree to logs/01-21-all/4/omdt-inventory_management/tree.dot
2025-01-21 17:48:44,534 - decision_tree.py - exported decision tree visualization to logs/01-21-all/4/omdt-inventory_management/tree.png
2025-01-21 17:48:44,534 - decision_tree.py - synthesis finished after 208.69 seconds

ColoringSmt = 0.059 s (0.0 %)
ColoringSmt:: create choice colors = 0.026 s (0.0 %)
ColoringSmt:: create harmonizing variants = 0.033 s (0.0 %)
areChoicesConsistent = 4.487 s (2.2 %)
areChoicesConsistent::1 is scheduler consistent? = 2.828 s (1.4 %)
areChoicesConsistent::2 better unsat core = 0.911 s (0.4 %)
areChoicesConsistent::3 unsat core analysis = 0.691 s (0.3 %)
check = 4.942 s (2.4 %)
loadUnsatCore = 0.003 s (0.0 %)
selectCompatibleChoices = 5.198 s (2.5 %)
selectCompatibleChoices::1 is family sat = 4.13 s (2.0 %)
selectCompatibleChoices::2 state exploration = 1.067 s (0.5 %)
