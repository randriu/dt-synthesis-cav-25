2025-01-21 18:07:46,785 - cli.py - This is Paynt version 0.1.0.
2025-01-21 18:07:46,785 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/qcomp/pnueli-zuck-3/model-random-enabled.drn ...
2025-01-21 18:07:46,785 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 18:07:46,999 - sketch.py - assuming sketch in DRN format...
2025-01-21 18:07:47,361 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/qcomp/pnueli-zuck-3/discounted.props ...
2025-01-21 18:07:47,361 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 18:07:47,363 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/qcomp/pnueli-zuck-3/state-valuations.json, adding to the model...
2025-01-21 18:07:47,365 - sketch.py - sketch parsing OK
2025-01-21 18:07:47,746 - sketch.py - constructed explicit quotient having 1950 states and 122850 choices
2025-01-21 18:07:47,746 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 18:07:47,755 - mdp.py - MDP has 1949/1950 relevant states
2025-01-21 18:07:48,928 - mdp.py - MDP has 63 actions
2025-01-21 18:07:48,935 - mdp.py - found the following 3 variables: ['p0:[0..15]', 'p1:[1..10]', 'p2:[0..15]']
2025-01-21 18:07:48,953 - decision_tree.py - the optimal scheduler has value: 0.96059601
2025-01-21 18:07:48,957 - decision_tree.py - the random scheduler has value: 0.6489813220663848

2025-01-21 18:07:48,957 - mdp.py - building tree of depth 0
2025-01-21 18:07:49,038 - statistic.py - synthesis initiated, design space: 63
2025-01-21 18:07:49,096 - synthesizer_ar.py - value 0.7422 achieved after 2.31 seconds
2025-01-21 18:07:49,102 - synthesizer_ar.py - value 0.7439 achieved after 2.32 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.13 s
number of holes: 1, family size: 63, quotient: 1950 states / 122850 actions
explored: 100 %
MDP stats: avg MDP size: 1908, iterations: 43

optimum: 0.74395
--------------------
2025-01-21 18:07:50,164 - decision_tree.py - families considered: 43
2025-01-21 18:07:50,164 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:07:50,164 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 18:07:50,164 - decision_tree.py - families model checked: 43
2025-01-21 18:07:50,164 - decision_tree.py - harmonizations attempted: 14
2025-01-21 18:07:50,164 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 18:07:50,164 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:07:50,164 - decision_tree.py - A_0=process1_cmd_27
2025-01-21 18:07:50,171 - decision_tree.py - double-checking specification satisfiability:  : 0.7439499353807243

2025-01-21 18:07:50,171 - mdp.py - building tree of depth 1
2025-01-21 18:07:50,473 - statistic.py - synthesis initiated, design space: 1e7
2025-01-21 18:07:51,322 - synthesizer_ar.py - value 0.7464 achieved after 4.54 seconds
> progress 0.108%, elapsed 3 s, estimated 2833 s, iters = {MDP: 69}, opt = 0.7464
2025-01-21 18:07:55,566 - synthesizer_ar.py - value 0.7466 achieved after 8.78 seconds
> progress 0.221%, elapsed 6 s, estimated 2760 s, iters = {MDP: 152}, opt = 0.7466
2025-01-21 18:07:56,781 - synthesizer_ar.py - value 0.7468 achieved after 10.0 seconds
2025-01-21 18:07:58,214 - synthesizer_ar.py - value 0.7473 achieved after 11.43 seconds
> progress 0.282%, elapsed 9 s, estimated 3228 s, iters = {MDP: 242}, opt = 0.7473
2025-01-21 18:08:00,000 - synthesizer_ar.py - value 0.75 achieved after 13.22 seconds
> progress 0.385%, elapsed 12 s, estimated 3153 s, iters = {MDP: 333}, opt = 0.75
> progress 0.436%, elapsed 15 s, estimated 3473 s, iters = {MDP: 431}, opt = 0.75
2025-01-21 18:08:08,324 - synthesizer_ar.py - value 0.8073 achieved after 21.54 seconds
> progress 0.556%, elapsed 18 s, estimated 3271 s, iters = {MDP: 538}, opt = 0.8073
> progress 2.391%, elapsed 21 s, estimated 887 s, iters = {MDP: 629}, opt = 0.8073
> progress 3.856%, elapsed 24 s, estimated 628 s, iters = {MDP: 719}, opt = 0.8073
> progress 12.599%, elapsed 27 s, estimated 216 s, iters = {MDP: 787}, opt = 0.8073
> progress 29.359%, elapsed 30 s, estimated 103 s, iters = {MDP: 852}, opt = 0.8073
> progress 29.756%, elapsed 33 s, estimated 112 s, iters = {MDP: 947}, opt = 0.8073
> progress 33.759%, elapsed 36 s, estimated 107 s, iters = {MDP: 1032}, opt = 0.8073
> progress 34.292%, elapsed 39 s, estimated 114 s, iters = {MDP: 1135}, opt = 0.8073
> progress 34.864%, elapsed 42 s, estimated 121 s, iters = {MDP: 1238}, opt = 0.8073
> progress 37.394%, elapsed 45 s, estimated 121 s, iters = {MDP: 1327}, opt = 0.8073
> progress 53.5%, elapsed 48 s, estimated 90 s, iters = {MDP: 1393}, opt = 0.8073
> progress 60.799%, elapsed 51 s, estimated 84 s, iters = {MDP: 1459}, opt = 0.8073
> progress 62.6%, elapsed 54 s, estimated 87 s, iters = {MDP: 1552}, opt = 0.8073
> progress 62.885%, elapsed 57 s, estimated 91 s, iters = {MDP: 1648}, opt = 0.8073
2025-01-21 18:08:50,426 - synthesizer_ar.py - value 0.8211 achieved after 63.64 seconds
> progress 67.14%, elapsed 60 s, estimated 90 s, iters = {MDP: 1734}, opt = 0.8211
2025-01-21 18:08:51,366 - synthesizer_ar.py - value 0.8212 achieved after 64.58 seconds
2025-01-21 18:08:51,396 - synthesizer_ar.py - value 0.8442 achieved after 64.61 seconds
> progress 100.544%, elapsed 63 s, estimated 63 s, iters = {MDP: 1822}, opt = 0.8442
> progress 103.895%, elapsed 66 s, estimated 64 s, iters = {MDP: 1914}, opt = 0.8442
> progress 129.364%, elapsed 69 s, estimated 53 s, iters = {MDP: 1982}, opt = 0.8442
> progress 134.291%, elapsed 72 s, estimated 54 s, iters = {MDP: 2077}, opt = 0.8442
> progress 158.791%, elapsed 75 s, estimated 47 s, iters = {MDP: 2147}, opt = 0.8442
> progress 166.7%, elapsed 78 s, estimated 47 s, iters = {MDP: 2233}, opt = 0.8442
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 80.96 s
number of holes: 6, family size: 1e7, quotient: 1950 states / 122850 actions
explored: 200 %
MDP stats: avg MDP size: 1892, iterations: 2293

optimum: 0.844248
--------------------
2025-01-21 18:09:11,428 - decision_tree.py - families considered: 2293
2025-01-21 18:09:11,428 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:09:11,428 - decision_tree.py - families with schedulers preserved: 77
2025-01-21 18:09:11,428 - decision_tree.py - families model checked: 2216
2025-01-21 18:09:11,428 - decision_tree.py - harmonizations attempted: 724
2025-01-21 18:09:11,428 - decision_tree.py - harmonizations succeeded: 7

2025-01-21 18:09:11,428 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:09:11,428 - decision_tree.py - V_0=p1, p0_0=0, p1_0=1, p2_0=0, A_1=process1_cmd_26, A_2=process1_cmd_27
2025-01-21 18:09:11,435 - decision_tree.py - double-checking specification satisfiability:  : 0.8442479507270727

2025-01-21 18:09:11,435 - mdp.py - building tree of depth 2
2025-01-21 18:09:11,994 - statistic.py - synthesis initiated, design space: 1e18
2025-01-21 18:09:14,711 - synthesizer_ar.py - value 0.8587 achieved after 87.93 seconds
> progress 0.012%, elapsed 3 s, estimated 23622 s (6 hours), iters = {MDP: 59}, opt = 0.8587
2025-01-21 18:09:15,599 - synthesizer_ar.py - value 0.8599 achieved after 88.81 seconds
2025-01-21 18:09:17,259 - synthesizer_ar.py - value 0.8658 achieved after 90.47 seconds
> progress 0.9%, elapsed 6 s, estimated 674 s, iters = {MDP: 121}, opt = 0.8658
2025-01-21 18:09:18,088 - synthesizer_ar.py - value 0.9418 achieved after 91.3 seconds
> progress 3.611%, elapsed 9 s, estimated 251 s, iters = {MDP: 193}, opt = 0.9418
> progress 3.746%, elapsed 12 s, estimated 323 s, iters = {MDP: 262}, opt = 0.9418
> progress 3.797%, elapsed 15 s, estimated 398 s, iters = {MDP: 335}, opt = 0.9418
> progress 6.728%, elapsed 18 s, estimated 269 s, iters = {MDP: 406}, opt = 0.9418
> progress 9.145%, elapsed 21 s, estimated 231 s, iters = {MDP: 466}, opt = 0.9418
> progress 10.099%, elapsed 24 s, estimated 239 s, iters = {MDP: 532}, opt = 0.9418
> progress 10.344%, elapsed 27 s, estimated 263 s, iters = {MDP: 599}, opt = 0.9418
> progress 13.392%, elapsed 30 s, estimated 225 s, iters = {MDP: 672}, opt = 0.9418
> progress 13.587%, elapsed 33 s, estimated 245 s, iters = {MDP: 741}, opt = 0.9418
> progress 14.043%, elapsed 36 s, estimated 259 s, iters = {MDP: 812}, opt = 0.9418
> progress 22.175%, elapsed 39 s, estimated 177 s, iters = {MDP: 883}, opt = 0.9418
> progress 22.211%, elapsed 42 s, estimated 191 s, iters = {MDP: 951}, opt = 0.9418
> progress 22.248%, elapsed 45 s, estimated 204 s, iters = {MDP: 1027}, opt = 0.9418
> progress 22.283%, elapsed 48 s, estimated 217 s, iters = {MDP: 1110}, opt = 0.9418
> progress 26.767%, elapsed 51 s, estimated 192 s, iters = {MDP: 1175}, opt = 0.9418
2025-01-21 18:10:03,877 - synthesizer_ar.py - value 0.9606 achieved after 137.09 seconds
> progress 33.677%, elapsed 54 s, estimated 161 s, iters = {MDP: 1251}, opt = 0.9606
> progress 45.153%, elapsed 57 s, estimated 127 s, iters = {MDP: 1325}, opt = 0.9606
> progress 61.625%, elapsed 60 s, estimated 98 s, iters = {MDP: 1396}, opt = 0.9606
> progress 65.772%, elapsed 63 s, estimated 96 s, iters = {MDP: 1471}, opt = 0.9606
> progress 72.167%, elapsed 66 s, estimated 92 s, iters = {MDP: 1545}, opt = 0.9606
> progress 75.823%, elapsed 69 s, estimated 91 s, iters = {MDP: 1616}, opt = 0.9606
> progress 76.279%, elapsed 72 s, estimated 95 s, iters = {MDP: 1689}, opt = 0.9606
> progress 86.722%, elapsed 75 s, estimated 87 s, iters = {MDP: 1767}, opt = 0.9606
> progress 92.648%, elapsed 78 s, estimated 84 s, iters = {MDP: 1836}, opt = 0.9606
> progress 96.81%, elapsed 81 s, estimated 84 s, iters = {MDP: 1907}, opt = 0.9606
> progress 97.287%, elapsed 84 s, estimated 87 s, iters = {MDP: 1980}, opt = 0.9606
> progress 98.437%, elapsed 87 s, estimated 89 s, iters = {MDP: 2050}, opt = 0.9606
> progress 98.469%, elapsed 90 s, estimated 92 s, iters = {MDP: 2128}, opt = 0.9606
> progress 98.765%, elapsed 93 s, estimated 95 s, iters = {MDP: 2197}, opt = 0.9606
> progress 98.78%, elapsed 96 s, estimated 98 s, iters = {MDP: 2277}, opt = 0.9606
> progress 99.016%, elapsed 99 s, estimated 100 s, iters = {MDP: 2352}, opt = 0.9606
> progress 100.011%, elapsed 103 s, estimated 102 s, iters = {MDP: 2433}, opt = 0.9606
> progress 101.949%, elapsed 106 s, estimated 103 s, iters = {MDP: 2508}, opt = 0.9606
> progress 102.215%, elapsed 109 s, estimated 106 s, iters = {MDP: 2576}, opt = 0.9606
> progress 102.222%, elapsed 112 s, estimated 109 s, iters = {MDP: 2654}, opt = 0.9606
> progress 102.802%, elapsed 115 s, estimated 111 s, iters = {MDP: 2721}, opt = 0.9606
> progress 102.939%, elapsed 118 s, estimated 114 s, iters = {MDP: 2789}, opt = 0.9606
> progress 102.946%, elapsed 121 s, estimated 117 s, iters = {MDP: 2861}, opt = 0.9606
> progress 102.956%, elapsed 124 s, estimated 120 s, iters = {MDP: 2933}, opt = 0.9606
> progress 102.956%, elapsed 127 s, estimated 123 s, iters = {MDP: 3010}, opt = 0.9606
> progress 102.963%, elapsed 130 s, estimated 126 s, iters = {MDP: 3079}, opt = 0.9606
> progress 103.611%, elapsed 133 s, estimated 128 s, iters = {MDP: 3150}, opt = 0.9606
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 136.21 s
number of holes: 16, family size: 1e18, quotient: 1950 states / 122850 actions
explored: 103 %
MDP stats: avg MDP size: 1830, iterations: 3225

optimum: 0.960596
--------------------
2025-01-21 18:11:28,205 - decision_tree.py - families considered: 3225
2025-01-21 18:11:28,205 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:11:28,205 - decision_tree.py - families with schedulers preserved: 1133
2025-01-21 18:11:28,205 - decision_tree.py - families model checked: 2092
2025-01-21 18:11:28,205 - decision_tree.py - harmonizations attempted: 116
2025-01-21 18:11:28,205 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 18:11:28,205 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:11:28,205 - decision_tree.py - V_0=p1, p0_0=1, p1_0=2, p2_0=0, V_1=p1, p0_1=0, p1_1=1, p2_1=0, A_2=process1_cmd_26, A_3=process1_cmd_27, V_4=p1, p0_4=0, p1_4=3, p2_4=0, A_5=process1_cmd_29, A_6=process1_cmd_32
2025-01-21 18:11:28,209 - decision_tree.py - double-checking specification satisfiability:  : 0.96059601
2025-01-21 18:11:28,209 - decision_tree.py - the optimal scheduler has value: 0.96059601
2025-01-21 18:11:28,209 - decision_tree.py - the random scheduler has value: 0.6489813220663848
2025-01-21 18:11:28,210 - decision_tree.py - synthesized tree of depth 2 with 3 decision nodes
2025-01-21 18:11:28,210 - decision_tree.py - the synthesized tree has value 0.96059601
2025-01-21 18:11:28,210 - decision_tree.py - the synthesized tree has relative value: 1.0
2025-01-21 18:11:28,210 - decision_tree.py - printing the synthesized tree below:
if p1<=2:
  if p1<=1:
    process1_cmd_26
  else:
    process1_cmd_27
else:
  if p1<=3:
    process1_cmd_29
  else:
    process1_cmd_32

2025-01-21 18:11:28,290 - decision_tree.py - exported decision tree to logs/01-21-all/4/qcomp-pnueli-zuck-3/tree.dot
2025-01-21 18:11:28,335 - decision_tree.py - exported decision tree visualization to logs/01-21-all/4/qcomp-pnueli-zuck-3/tree.png
2025-01-21 18:11:28,335 - decision_tree.py - synthesis finished after 221.55 seconds

ColoringSmt = 0.459 s (0.2 %)
ColoringSmt:: create choice colors = 0.209 s (0.1 %)
ColoringSmt:: create harmonizing variants = 0.248 s (0.1 %)
areChoicesConsistent = 12.496 s (5.6 %)
areChoicesConsistent::1 is scheduler consistent? = 7.357 s (3.3 %)
areChoicesConsistent::2 better unsat core = 2.616 s (1.2 %)
areChoicesConsistent::3 unsat core analysis = 2.466 s (1.1 %)
check = 9.337 s (4.2 %)
loadUnsatCore = 0.013 s (0.0 %)
selectCompatibleChoices = 28.463 s (12.8 %)
selectCompatibleChoices::1 is family sat = 16.419 s (7.4 %)
selectCompatibleChoices::2 state exploration = 12.041 s (5.4 %)
