2025-01-21 18:09:14,325 - cli.py - This is Paynt version 0.1.0.
2025-01-21 18:09:14,325 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/qcomp/resource-gathering-5/model-random-enabled.drn ...
2025-01-21 18:09:14,325 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 18:09:14,348 - sketch.py - assuming sketch in DRN format...
2025-01-21 18:09:14,371 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/qcomp/resource-gathering-5/discounted.props ...
2025-01-21 18:09:14,371 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 18:09:14,376 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/qcomp/resource-gathering-5/state-valuations.json, adding to the model...
2025-01-21 18:09:14,379 - sketch.py - sketch parsing OK
2025-01-21 18:09:14,383 - sketch.py - constructed explicit quotient having 3292 states and 16460 choices
2025-01-21 18:09:14,383 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 18:09:14,391 - mdp.py - MDP has 3291/3292 relevant states
2025-01-21 18:09:14,415 - mdp.py - MDP has 5 actions
2025-01-21 18:09:14,432 - mdp.py - found the following 7 variables: ['attacked:[0..1]', 'gem:[0..1]', 'gold:[0..1]', 'required_gem:[0..5]', 'required_gold:[0..5]', 'x:[1..5]', 'y:[1..5]']
2025-01-21 18:09:14,438 - decision_tree.py - the optimal scheduler has value: -47.71054759664841
2025-01-21 18:09:14,444 - decision_tree.py - the random scheduler has value: -99.87697400578439

2025-01-21 18:09:14,444 - mdp.py - building tree of depth 0
2025-01-21 18:09:14,470 - statistic.py - synthesis initiated, design space: 5
2025-01-21 18:09:14,480 - synthesizer_ar.py - value -99.9956 achieved after 0.15 seconds
2025-01-21 18:09:14,506 - synthesizer_ar.py - value -99.877 achieved after 0.18 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.04 s
number of holes: 1, family size: 5, quotient: 3292 states / 16460 actions
explored: 100 %
MDP stats: avg MDP size: 1420, iterations: 7

optimum: -99.876974
--------------------
2025-01-21 18:09:14,512 - decision_tree.py - families considered: 7
2025-01-21 18:09:14,512 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:09:14,512 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 18:09:14,512 - decision_tree.py - families model checked: 7
2025-01-21 18:09:14,512 - decision_tree.py - harmonizations attempted: 2
2025-01-21 18:09:14,512 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 18:09:14,512 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:09:14,512 - decision_tree.py - A_0=__random__
2025-01-21 18:09:14,518 - decision_tree.py - double-checking specification satisfiability:  : -99.87697400578439

2025-01-21 18:09:14,518 - mdp.py - building tree of depth 1
2025-01-21 18:09:14,662 - statistic.py - synthesis initiated, design space: 70000
2025-01-21 18:09:14,753 - synthesizer_ar.py - value -99.874 achieved after 0.43 seconds
2025-01-21 18:09:14,939 - synthesizer_ar.py - value -99.8542 achieved after 0.61 seconds
2025-01-21 18:09:15,009 - synthesizer_ar.py - value -95.1392 achieved after 0.68 seconds
> progress 184.571%, elapsed 3 s, estimated 1 s, iters = {MDP: 269}, opt = -95.1392
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 3.27 s
number of holes: 10, family size: 70000, quotient: 3292 states / 16460 actions
explored: 200 %
MDP stats: avg MDP size: 1793, iterations: 286

optimum: -95.139217
--------------------
2025-01-21 18:09:17,937 - decision_tree.py - families considered: 286
2025-01-21 18:09:17,938 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:09:17,938 - decision_tree.py - families with schedulers preserved: 33
2025-01-21 18:09:17,938 - decision_tree.py - families model checked: 253
2025-01-21 18:09:17,938 - decision_tree.py - harmonizations attempted: 72
2025-01-21 18:09:17,938 - decision_tree.py - harmonizations succeeded: 3

2025-01-21 18:09:17,938 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:09:17,938 - decision_tree.py - V_0=gem, attacked_0=0, gem_0=0, gold_0=0, required_gem_0=0, required_gold_0=0, x_0=1, y_0=1, A_1=top, A_2=down
2025-01-21 18:09:17,939 - decision_tree.py - double-checking specification satisfiability:  : -95.13921708639764

2025-01-21 18:09:17,939 - mdp.py - building tree of depth 2
2025-01-21 18:09:18,401 - statistic.py - synthesis initiated, design space: 1e13
2025-01-21 18:09:19,399 - synthesizer_ar.py - value -94.1246 achieved after 5.07 seconds
2025-01-21 18:09:20,828 - synthesizer_ar.py - value -92.8589 achieved after 6.5 seconds
> progress 0.107%, elapsed 3 s, estimated 2787 s, iters = {MDP: 342}, opt = -92.8589
2025-01-21 18:09:22,284 - synthesizer_ar.py - value -91.6598 achieved after 7.96 seconds
> progress 0.305%, elapsed 6 s, estimated 1969 s, iters = {MDP: 670}, opt = -91.6598
2025-01-21 18:09:25,503 - synthesizer_ar.py - value -90.4542 achieved after 11.18 seconds
> progress 0.725%, elapsed 9 s, estimated 1245 s, iters = {MDP: 970}, opt = -90.4542
> progress 1.44%, elapsed 12 s, estimated 835 s, iters = {MDP: 1204}, opt = -90.4542
> progress 1.532%, elapsed 15 s, estimated 982 s, iters = {MDP: 1378}, opt = -90.4542
> progress 4.107%, elapsed 18 s, estimated 439 s, iters = {MDP: 1647}, opt = -90.4542
> progress 4.288%, elapsed 21 s, estimated 491 s, iters = {MDP: 1989}, opt = -90.4542
> progress 4.6%, elapsed 24 s, estimated 523 s, iters = {MDP: 2323}, opt = -90.4542
> progress 4.806%, elapsed 27 s, estimated 563 s, iters = {MDP: 2622}, opt = -90.4542
> progress 4.839%, elapsed 30 s, estimated 621 s, iters = {MDP: 2872}, opt = -90.4542
> progress 4.887%, elapsed 33 s, estimated 678 s, iters = {MDP: 3105}, opt = -90.4542
> progress 5.495%, elapsed 36 s, estimated 658 s, iters = {MDP: 3223}, opt = -90.4542
> progress 5.567%, elapsed 39 s, estimated 703 s, iters = {MDP: 3349}, opt = -90.4542
> progress 5.602%, elapsed 42 s, estimated 754 s, iters = {MDP: 3444}, opt = -90.4542
> progress 5.672%, elapsed 45 s, estimated 798 s, iters = {MDP: 3556}, opt = -90.4542
2025-01-21 18:10:04,792 - synthesizer_ar.py - value -90.1493 achieved after 50.47 seconds
2025-01-21 18:10:05,253 - synthesizer_ar.py - value -68.6287 achieved after 50.93 seconds
2025-01-21 18:10:05,313 - synthesizer_ar.py - value -53.9064 achieved after 50.99 seconds
> progress 14.769%, elapsed 48 s, estimated 326 s, iters = {MDP: 3893}, opt = -53.9064
> progress 25.816%, elapsed 51 s, estimated 198 s, iters = {MDP: 4243}, opt = -53.9064
> progress 42.979%, elapsed 54 s, estimated 126 s, iters = {MDP: 4592}, opt = -53.9064
> progress 45.107%, elapsed 57 s, estimated 127 s, iters = {MDP: 4964}, opt = -53.9064
> progress 49.62%, elapsed 60 s, estimated 121 s, iters = {MDP: 5349}, opt = -53.9064
> progress 61.865%, elapsed 63 s, estimated 102 s, iters = {MDP: 5703}, opt = -53.9064
> progress 67.79%, elapsed 66 s, estimated 97 s, iters = {MDP: 6071}, opt = -53.9064
> progress 73.154%, elapsed 69 s, estimated 94 s, iters = {MDP: 6429}, opt = -53.9064
> progress 83.72%, elapsed 72 s, estimated 86 s, iters = {MDP: 6818}, opt = -53.9064
> progress 90.845%, elapsed 75 s, estimated 82 s, iters = {MDP: 7162}, opt = -53.9064
> progress 94.008%, elapsed 78 s, estimated 83 s, iters = {MDP: 7554}, opt = -53.9064
> progress 97.145%, elapsed 81 s, estimated 83 s, iters = {MDP: 7884}, opt = -53.9064
> progress 100.65%, elapsed 84 s, estimated 83 s, iters = {MDP: 8257}, opt = -53.9064
> progress 107.026%, elapsed 87 s, estimated 81 s, iters = {MDP: 8613}, opt = -53.9064
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 89.98 s
number of holes: 28, family size: 1e13, quotient: 3292 states / 16460 actions
explored: 114 %
MDP stats: avg MDP size: 1660, iterations: 8881

optimum: -53.906396
--------------------
2025-01-21 18:10:48,384 - decision_tree.py - families considered: 8881
2025-01-21 18:10:48,384 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:10:48,384 - decision_tree.py - families with schedulers preserved: 1739
2025-01-21 18:10:48,384 - decision_tree.py - families model checked: 7142
2025-01-21 18:10:48,384 - decision_tree.py - harmonizations attempted: 1583
2025-01-21 18:10:48,384 - decision_tree.py - harmonizations succeeded: 4

2025-01-21 18:10:48,384 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:10:48,384 - decision_tree.py - V_0=gem, attacked_0=0, gem_0=0, gold_0=0, required_gem_0=0, required_gold_0=0, x_0=1, y_0=1, V_1=y, attacked_1=0, gem_1=0, gold_1=0, required_gem_1=0, required_gold_1=0, x_1=1, y_1=4, A_2=top, A_3=right, V_4=y, attacked_4=0, gem_4=0, gold_4=0, required_gem_4=0, required_gold_4=0, x_4=1, y_4=1, A_5=left, A_6=down
2025-01-21 18:10:48,386 - decision_tree.py - double-checking specification satisfiability:  : -53.90639575082535

2025-01-21 18:10:48,386 - mdp.py - building tree of depth 3
2025-01-21 18:10:49,248 - statistic.py - synthesis initiated, design space: 1e29
2025-01-21 18:10:49,325 - synthesizer_ar.py - value -47.7105 achieved after 95.0 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.51 s
number of holes: 64, family size: 1e29, quotient: 3292 states / 16460 actions
explored: 100 %
MDP stats: avg MDP size: 3032, iterations: 36

optimum: -47.710539
--------------------
2025-01-21 18:10:49,755 - decision_tree.py - families considered: 36
2025-01-21 18:10:49,755 - decision_tree.py - families skipped by construction: 0
2025-01-21 18:10:49,755 - decision_tree.py - families with schedulers preserved: 11
2025-01-21 18:10:49,755 - decision_tree.py - families model checked: 25
2025-01-21 18:10:49,755 - decision_tree.py - harmonizations attempted: 1
2025-01-21 18:10:49,755 - decision_tree.py - harmonizations succeeded: 0

2025-01-21 18:10:49,755 - decision_tree.py - printing synthesized assignment below:
2025-01-21 18:10:49,755 - decision_tree.py - V_0=gem, attacked_0=0, gem_0=0, gold_0=0, required_gem_0=0, required_gold_0=0, x_0=1, y_0=1, V_1=y, attacked_1=0, gem_1=0, gold_1=0, required_gem_1=0, required_gold_1=0, x_1=1, y_1=4, V_2=required_gold, attacked_2=0, gem_2=0, gold_2=0, required_gem_2=0, required_gold_2=0, x_2=1, y_2=1, A_3=down, A_4=top, V_5=x, attacked_5=0, gem_5=0, gold_5=0, required_gem_5=0, required_gold_5=4, x_5=4, y_5=1, A_6=right, A_7=down, V_8=y, attacked_8=0, gem_8=0, gold_8=0, required_gem_8=0, required_gold_8=0, x_8=1, y_8=1, V_9=required_gold, attacked_9=0, gem_9=0, gold_9=0, required_gem_9=0, required_gold_9=1, x_9=1, y_9=1, A_10=left, A_11=left, V_12=gem, attacked_12=0, gem_12=0, gold_12=0, required_gem_12=0, required_gold_12=0, x_12=1, y_12=1, A_13=__random__, A_14=down
2025-01-21 18:10:49,757 - decision_tree.py - double-checking specification satisfiability:  : -47.71053916989508
2025-01-21 18:10:49,758 - decision_tree.py - the optimal scheduler has value: -47.71054759664841
2025-01-21 18:10:49,758 - decision_tree.py - the random scheduler has value: -99.87697400578439
2025-01-21 18:10:49,759 - decision_tree.py - synthesized tree of depth 3 with 5 decision nodes
2025-01-21 18:10:49,759 - decision_tree.py - the synthesized tree has value -47.71053916989508
2025-01-21 18:10:49,759 - decision_tree.py - the synthesized tree has relative value: 1.0000001615359517
2025-01-21 18:10:49,759 - decision_tree.py - printing the synthesized tree below:
if gem<=0:
  if y<=4:
    if required_gold<=0:
      down
    else:
      top
  else:
    if x<=4:
      right
    else:
      down
else:
  if y<=1:
    left
  else:
    down

2025-01-21 18:10:49,762 - decision_tree.py - exported decision tree to logs/01-21-all/4/qcomp-resource-gathering-5/tree.dot
2025-01-21 18:10:49,808 - decision_tree.py - exported decision tree visualization to logs/01-21-all/4/qcomp-resource-gathering-5/tree.png
2025-01-21 18:10:49,808 - decision_tree.py - synthesis finished after 95.48 seconds

ColoringSmt = 0.822 s (0.9 %)
ColoringSmt:: create choice colors = 0.189 s (0.2 %)
ColoringSmt:: create harmonizing variants = 0.631 s (0.7 %)
areChoicesConsistent = 0.161 s (0.2 %)
areChoicesConsistent::1 is scheduler consistent? = 0.084 s (0.1 %)
areChoicesConsistent::2 better unsat core = 0.045 s (0.0 %)
areChoicesConsistent::3 unsat core analysis = 0.028 s (0.0 %)
check = 0.136 s (0.1 %)
loadUnsatCore = 0.0 s (0.0 %)
selectCompatibleChoices = 0.177 s (0.2 %)
selectCompatibleChoices::1 is family sat = 0.102 s (0.1 %)
selectCompatibleChoices::2 state exploration = 0.074 s (0.1 %)
