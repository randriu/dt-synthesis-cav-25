2025-01-21 17:14:23,874 - cli.py - This is Paynt version 0.1.0.
2025-01-21 17:14:23,874 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/qcomp/pnueli-zuck-3/model-random-enabled.drn ...
2025-01-21 17:14:23,874 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 17:14:24,090 - sketch.py - assuming sketch in DRN format...
2025-01-21 17:14:24,455 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/qcomp/pnueli-zuck-3/discounted.props ...
2025-01-21 17:14:24,456 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 17:14:24,457 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/qcomp/pnueli-zuck-3/state-valuations.json, adding to the model...
2025-01-21 17:14:24,460 - sketch.py - sketch parsing OK
2025-01-21 17:14:24,832 - sketch.py - constructed explicit quotient having 1950 states and 122850 choices
2025-01-21 17:14:24,832 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 17:14:24,841 - mdp.py - MDP has 1949/1950 relevant states
2025-01-21 17:14:25,999 - mdp.py - MDP has 63 actions
2025-01-21 17:14:26,006 - mdp.py - found the following 3 variables: ['p0:[0..15]', 'p1:[1..10]', 'p2:[0..15]']
2025-01-21 17:14:26,022 - decision_tree.py - the optimal scheduler has value: 0.96059601
2025-01-21 17:14:26,027 - decision_tree.py - the random scheduler has value: 0.6489813220663848

2025-01-21 17:14:26,027 - mdp.py - building tree of depth 0
2025-01-21 17:14:26,106 - statistic.py - synthesis initiated, design space: 63
2025-01-21 17:14:26,165 - synthesizer_ar.py - value 0.7422 achieved after 2.29 seconds
2025-01-21 17:14:26,171 - synthesizer_ar.py - value 0.7439 achieved after 2.3 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 1.12 s
number of holes: 1, family size: 63, quotient: 1950 states / 122850 actions
explored: 100 %
MDP stats: avg MDP size: 1908, iterations: 43

optimum: 0.74395
--------------------
2025-01-21 17:14:27,227 - decision_tree.py - families considered: 43
2025-01-21 17:14:27,227 - decision_tree.py - families skipped by construction: 0
2025-01-21 17:14:27,227 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 17:14:27,227 - decision_tree.py - families model checked: 43
2025-01-21 17:14:27,227 - decision_tree.py - harmonizations attempted: 14
2025-01-21 17:14:27,227 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 17:14:27,227 - decision_tree.py - printing synthesized assignment below:
2025-01-21 17:14:27,227 - decision_tree.py - A_0=process1_cmd_27
2025-01-21 17:14:27,234 - decision_tree.py - double-checking specification satisfiability:  : 0.7439499353807243

2025-01-21 17:14:27,234 - mdp.py - building tree of depth 1
2025-01-21 17:14:27,532 - statistic.py - synthesis initiated, design space: 1e7
2025-01-21 17:14:28,372 - synthesizer_ar.py - value 0.7464 achieved after 4.5 seconds
> progress 0.108%, elapsed 3 s, estimated 2826 s, iters = {MDP: 69}, opt = 0.7464
2025-01-21 17:14:32,619 - synthesizer_ar.py - value 0.7466 achieved after 8.75 seconds
> progress 0.221%, elapsed 6 s, estimated 2757 s, iters = {MDP: 152}, opt = 0.7466
2025-01-21 17:14:33,836 - synthesizer_ar.py - value 0.7468 achieved after 9.96 seconds
2025-01-21 17:14:35,261 - synthesizer_ar.py - value 0.7473 achieved after 11.39 seconds
> progress 0.283%, elapsed 9 s, estimated 3213 s, iters = {MDP: 243}, opt = 0.7473
2025-01-21 17:14:37,027 - synthesizer_ar.py - value 0.75 achieved after 13.15 seconds
> progress 0.386%, elapsed 12 s, estimated 3135 s, iters = {MDP: 335}, opt = 0.75
> progress 0.437%, elapsed 15 s, estimated 3451 s, iters = {MDP: 433}, opt = 0.75
2025-01-21 17:14:45,292 - synthesizer_ar.py - value 0.8073 achieved after 21.42 seconds
> progress 0.556%, elapsed 18 s, estimated 3255 s, iters = {MDP: 538}, opt = 0.8073
> progress 2.391%, elapsed 21 s, estimated 883 s, iters = {MDP: 630}, opt = 0.8073
> progress 3.864%, elapsed 24 s, estimated 624 s, iters = {MDP: 720}, opt = 0.8073
> progress 12.599%, elapsed 27 s, estimated 215 s, iters = {MDP: 787}, opt = 0.8073
> progress 29.359%, elapsed 30 s, estimated 102 s, iters = {MDP: 852}, opt = 0.8073
> progress 29.756%, elapsed 33 s, estimated 111 s, iters = {MDP: 947}, opt = 0.8073
> progress 33.759%, elapsed 36 s, estimated 107 s, iters = {MDP: 1032}, opt = 0.8073
> progress 34.292%, elapsed 39 s, estimated 114 s, iters = {MDP: 1135}, opt = 0.8073
> progress 34.871%, elapsed 42 s, estimated 121 s, iters = {MDP: 1239}, opt = 0.8073
> progress 37.394%, elapsed 45 s, estimated 121 s, iters = {MDP: 1327}, opt = 0.8073
> progress 53.5%, elapsed 48 s, estimated 90 s, iters = {MDP: 1393}, opt = 0.8073
> progress 60.799%, elapsed 51 s, estimated 84 s, iters = {MDP: 1459}, opt = 0.8073
> progress 62.632%, elapsed 54 s, estimated 86 s, iters = {MDP: 1553}, opt = 0.8073
> progress 62.886%, elapsed 57 s, estimated 91 s, iters = {MDP: 1650}, opt = 0.8073
2025-01-21 17:15:27,293 - synthesizer_ar.py - value 0.8211 achieved after 63.42 seconds
> progress 67.14%, elapsed 60 s, estimated 89 s, iters = {MDP: 1735}, opt = 0.8211
2025-01-21 17:15:28,237 - synthesizer_ar.py - value 0.8212 achieved after 64.36 seconds
2025-01-21 17:15:28,268 - synthesizer_ar.py - value 0.8442 achieved after 64.39 seconds
> progress 100.544%, elapsed 63 s, estimated 63 s, iters = {MDP: 1822}, opt = 0.8442
> progress 103.895%, elapsed 66 s, estimated 63 s, iters = {MDP: 1913}, opt = 0.8442
> progress 129.334%, elapsed 69 s, estimated 53 s, iters = {MDP: 1980}, opt = 0.8442
> progress 134.29%, elapsed 72 s, estimated 53 s, iters = {MDP: 2074}, opt = 0.8442
> progress 158.758%, elapsed 75 s, estimated 47 s, iters = {MDP: 2145}, opt = 0.8442
> progress 166.683%, elapsed 78 s, estimated 47 s, iters = {MDP: 2230}, opt = 0.8442
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 80.84 s
number of holes: 6, family size: 1e7, quotient: 1950 states / 122850 actions
explored: 200 %
MDP stats: avg MDP size: 1892, iterations: 2293

optimum: 0.844248
--------------------
2025-01-21 17:15:48,371 - decision_tree.py - families considered: 2293
2025-01-21 17:15:48,371 - decision_tree.py - families skipped by construction: 0
2025-01-21 17:15:48,371 - decision_tree.py - families with schedulers preserved: 77
2025-01-21 17:15:48,371 - decision_tree.py - families model checked: 2216
2025-01-21 17:15:48,371 - decision_tree.py - harmonizations attempted: 724
2025-01-21 17:15:48,371 - decision_tree.py - harmonizations succeeded: 7

2025-01-21 17:15:48,371 - decision_tree.py - printing synthesized assignment below:
2025-01-21 17:15:48,371 - decision_tree.py - V_0=p1, p0_0=0, p1_0=1, p2_0=0, A_1=process1_cmd_26, A_2=process1_cmd_27
2025-01-21 17:15:48,377 - decision_tree.py - double-checking specification satisfiability:  : 0.8442479507270727

2025-01-21 17:15:48,378 - mdp.py - building tree of depth 2
2025-01-21 17:15:48,932 - statistic.py - synthesis initiated, design space: 1e18
2025-01-21 17:15:51,663 - synthesizer_ar.py - value 0.8587 achieved after 87.79 seconds
> progress 0.012%, elapsed 3 s, estimated 23742 s (6 hours), iters = {MDP: 59}, opt = 0.8587
2025-01-21 17:15:52,558 - synthesizer_ar.py - value 0.8599 achieved after 88.68 seconds
2025-01-21 17:15:54,248 - synthesizer_ar.py - value 0.8658 achieved after 90.37 seconds
> progress 0.896%, elapsed 6 s, estimated 679 s, iters = {MDP: 119}, opt = 0.8658
2025-01-21 17:15:55,086 - synthesizer_ar.py - value 0.9418 achieved after 91.21 seconds
> progress 3.611%, elapsed 9 s, estimated 252 s, iters = {MDP: 192}, opt = 0.9418
> progress 3.746%, elapsed 12 s, estimated 323 s, iters = {MDP: 260}, opt = 0.9418
> progress 3.797%, elapsed 15 s, estimated 399 s, iters = {MDP: 334}, opt = 0.9418
> progress 6.725%, elapsed 18 s, estimated 270 s, iters = {MDP: 405}, opt = 0.9418
> progress 9.145%, elapsed 21 s, estimated 232 s, iters = {MDP: 466}, opt = 0.9418
> progress 10.099%, elapsed 24 s, estimated 240 s, iters = {MDP: 532}, opt = 0.9418
> progress 10.344%, elapsed 27 s, estimated 264 s, iters = {MDP: 599}, opt = 0.9418
> progress 13.392%, elapsed 30 s, estimated 226 s, iters = {MDP: 672}, opt = 0.9418
> progress 13.587%, elapsed 33 s, estimated 245 s, iters = {MDP: 741}, opt = 0.9418
> progress 14.043%, elapsed 36 s, estimated 259 s, iters = {MDP: 812}, opt = 0.9418
> progress 22.175%, elapsed 39 s, estimated 178 s, iters = {MDP: 882}, opt = 0.9418
> progress 22.211%, elapsed 42 s, estimated 191 s, iters = {MDP: 950}, opt = 0.9418
> progress 22.248%, elapsed 45 s, estimated 204 s, iters = {MDP: 1026}, opt = 0.9418
> progress 22.283%, elapsed 48 s, estimated 218 s, iters = {MDP: 1109}, opt = 0.9418
> progress 26.767%, elapsed 51 s, estimated 192 s, iters = {MDP: 1174}, opt = 0.9418
2025-01-21 17:16:40,919 - synthesizer_ar.py - value 0.9606 achieved after 137.05 seconds
> progress 33.677%, elapsed 54 s, estimated 162 s, iters = {MDP: 1250}, opt = 0.9606
> progress 45.153%, elapsed 57 s, estimated 127 s, iters = {MDP: 1324}, opt = 0.9606
> progress 61.578%, elapsed 60 s, estimated 98 s, iters = {MDP: 1395}, opt = 0.9606
> progress 65.697%, elapsed 63 s, estimated 96 s, iters = {MDP: 1470}, opt = 0.9606
> progress 72.166%, elapsed 66 s, estimated 92 s, iters = {MDP: 1543}, opt = 0.9606
> progress 75.823%, elapsed 69 s, estimated 91 s, iters = {MDP: 1615}, opt = 0.9606
> progress 76.279%, elapsed 72 s, estimated 95 s, iters = {MDP: 1686}, opt = 0.9606
> progress 86.722%, elapsed 75 s, estimated 87 s, iters = {MDP: 1763}, opt = 0.9606
> progress 92.632%, elapsed 78 s, estimated 85 s, iters = {MDP: 1833}, opt = 0.9606
> progress 93.682%, elapsed 81 s, estimated 87 s, iters = {MDP: 1904}, opt = 0.9606
> progress 97.287%, elapsed 84 s, estimated 87 s, iters = {MDP: 1976}, opt = 0.9606
> progress 98.437%, elapsed 87 s, estimated 89 s, iters = {MDP: 2045}, opt = 0.9606
> progress 98.469%, elapsed 90 s, estimated 92 s, iters = {MDP: 2124}, opt = 0.9606
> progress 98.764%, elapsed 93 s, estimated 95 s, iters = {MDP: 2193}, opt = 0.9606
> progress 98.779%, elapsed 96 s, estimated 98 s, iters = {MDP: 2273}, opt = 0.9606
> progress 99.015%, elapsed 99 s, estimated 100 s, iters = {MDP: 2347}, opt = 0.9606
> progress 99.282%, elapsed 102 s, estimated 103 s, iters = {MDP: 2427}, opt = 0.9606
> progress 101.949%, elapsed 105 s, estimated 103 s, iters = {MDP: 2502}, opt = 0.9606
> progress 102.215%, elapsed 109 s, estimated 106 s, iters = {MDP: 2572}, opt = 0.9606
> progress 102.219%, elapsed 112 s, estimated 109 s, iters = {MDP: 2650}, opt = 0.9606
> progress 102.776%, elapsed 115 s, estimated 111 s, iters = {MDP: 2717}, opt = 0.9606
> progress 102.939%, elapsed 118 s, estimated 114 s, iters = {MDP: 2786}, opt = 0.9606
> progress 102.946%, elapsed 121 s, estimated 117 s, iters = {MDP: 2856}, opt = 0.9606
> progress 102.956%, elapsed 124 s, estimated 120 s, iters = {MDP: 2929}, opt = 0.9606
> progress 102.956%, elapsed 127 s, estimated 123 s, iters = {MDP: 3006}, opt = 0.9606
> progress 102.962%, elapsed 130 s, estimated 126 s, iters = {MDP: 3075}, opt = 0.9606
> progress 103.611%, elapsed 133 s, estimated 128 s, iters = {MDP: 3144}, opt = 0.9606
> progress 103.7%, elapsed 136 s, estimated 131 s, iters = {MDP: 3221}, opt = 0.9606
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 136.36 s
number of holes: 16, family size: 1e18, quotient: 1950 states / 122850 actions
explored: 103 %
MDP stats: avg MDP size: 1830, iterations: 3225

optimum: 0.960596
--------------------
2025-01-21 17:18:05,297 - decision_tree.py - families considered: 3225
2025-01-21 17:18:05,297 - decision_tree.py - families skipped by construction: 0
2025-01-21 17:18:05,297 - decision_tree.py - families with schedulers preserved: 1133
2025-01-21 17:18:05,297 - decision_tree.py - families model checked: 2092
2025-01-21 17:18:05,297 - decision_tree.py - harmonizations attempted: 116
2025-01-21 17:18:05,297 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 17:18:05,297 - decision_tree.py - printing synthesized assignment below:
2025-01-21 17:18:05,297 - decision_tree.py - V_0=p1, p0_0=1, p1_0=2, p2_0=0, V_1=p1, p0_1=0, p1_1=1, p2_1=0, A_2=process1_cmd_26, A_3=process1_cmd_27, V_4=p1, p0_4=0, p1_4=3, p2_4=0, A_5=process1_cmd_29, A_6=process1_cmd_32
2025-01-21 17:18:05,301 - decision_tree.py - double-checking specification satisfiability:  : 0.96059601
2025-01-21 17:18:05,301 - decision_tree.py - the optimal scheduler has value: 0.96059601
2025-01-21 17:18:05,301 - decision_tree.py - the random scheduler has value: 0.6489813220663848
2025-01-21 17:18:05,302 - decision_tree.py - synthesized tree of depth 2 with 3 decision nodes
2025-01-21 17:18:05,302 - decision_tree.py - the synthesized tree has value 0.96059601
2025-01-21 17:18:05,302 - decision_tree.py - the synthesized tree has relative value: 1.0
2025-01-21 17:18:05,302 - decision_tree.py - printing the synthesized tree below:
if p1<=2:
  if p1<=1:
    process1_cmd_26
  else:
    process1_cmd_27
else:
  if p1<=3:
    process1_cmd_29
  else:
    process1_cmd_32

2025-01-21 17:18:05,373 - decision_tree.py - exported decision tree to logs/01-21-all/3/qcomp-pnueli-zuck-3/tree.dot
2025-01-21 17:18:05,416 - decision_tree.py - exported decision tree visualization to logs/01-21-all/3/qcomp-pnueli-zuck-3/tree.png
2025-01-21 17:18:05,416 - decision_tree.py - synthesis finished after 221.54 seconds

ColoringSmt = 0.454 s (0.2 %)
ColoringSmt:: create choice colors = 0.205 s (0.1 %)
ColoringSmt:: create harmonizing variants = 0.247 s (0.1 %)
areChoicesConsistent = 12.587 s (5.7 %)
areChoicesConsistent::1 is scheduler consistent? = 7.426 s (3.4 %)
areChoicesConsistent::2 better unsat core = 2.616 s (1.2 %)
areChoicesConsistent::3 unsat core analysis = 2.484 s (1.1 %)
check = 9.393 s (4.2 %)
loadUnsatCore = 0.016 s (0.0 %)
selectCompatibleChoices = 28.533 s (12.9 %)
selectCompatibleChoices::1 is family sat = 16.495 s (7.4 %)
selectCompatibleChoices::2 state exploration = 12.034 s (5.4 %)
