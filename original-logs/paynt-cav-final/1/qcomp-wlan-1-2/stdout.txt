2025-01-21 15:52:21,580 - cli.py - This is Paynt version 0.1.0.
2025-01-21 15:52:21,580 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/qcomp/wlan-1-2/model-random-enabled.drn ...
2025-01-21 15:52:21,580 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 15:52:21,694 - sketch.py - assuming sketch in DRN format...
2025-01-21 15:52:22,035 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/qcomp/wlan-1-2/discounted.props ...
2025-01-21 15:52:22,036 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 15:52:22,050 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/qcomp/wlan-1-2/state-valuations.json, adding to the model...
2025-01-21 15:52:22,056 - sketch.py - sketch parsing OK
2025-01-21 15:52:22,244 - sketch.py - constructed explicit quotient having 3127 states and 106318 choices
2025-01-21 15:52:22,244 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 15:52:22,252 - mdp.py - MDP has 3124/3127 relevant states
2025-01-21 15:52:22,818 - mdp.py - MDP has 34 actions
2025-01-21 15:52:22,841 - mdp.py - found the following 11 variables: ['backoff1:[0..15]', 'backoff2:[0..15]', 'bc1:[0..1]', 'bc2:[0..1]', 'c1:[0..2]', 'c2:[0..2]', 'col:[0..2]', 's1:[1..12]', 's2:[1..12]', 'x1:[0..10]', 'x2:[0..10]']
2025-01-21 15:52:22,853 - decision_tree.py - the optimal scheduler has value: 0.10827098374814313
2025-01-21 15:52:22,856 - decision_tree.py - the random scheduler has value: 0.02730039610596835

2025-01-21 15:52:22,857 - mdp.py - building tree of depth 0
2025-01-21 15:52:22,933 - statistic.py - synthesis initiated, design space: 34
2025-01-21 15:52:22,981 - synthesizer_ar.py - value 0.0274 achieved after 1.4 seconds
2025-01-21 15:52:22,987 - synthesizer_ar.py - value 0.0382 achieved after 1.41 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.59 s
number of holes: 1, family size: 34, quotient: 3127 states / 106318 actions
explored: 100 %
MDP stats: avg MDP size: 3079, iterations: 31

optimum: 0.038173
--------------------
2025-01-21 15:52:23,528 - decision_tree.py - families considered: 31
2025-01-21 15:52:23,528 - decision_tree.py - families skipped by construction: 0
2025-01-21 15:52:23,528 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 15:52:23,528 - decision_tree.py - families model checked: 31
2025-01-21 15:52:23,528 - decision_tree.py - harmonizations attempted: 10
2025-01-21 15:52:23,528 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 15:52:23,528 - decision_tree.py - printing synthesized assignment below:
2025-01-21 15:52:23,528 - decision_tree.py - A_0=time
2025-01-21 15:52:23,534 - decision_tree.py - double-checking specification satisfiability:  : 0.038173480123536434

2025-01-21 15:52:23,534 - mdp.py - building tree of depth 1
2025-01-21 15:52:23,871 - statistic.py - synthesis initiated, design space: 1e11
2025-01-21 15:52:24,155 - synthesizer_ar.py - value 0.039 achieved after 2.57 seconds
2025-01-21 15:52:24,218 - synthesizer_ar.py - value 0.0395 achieved after 2.64 seconds
2025-01-21 15:52:25,329 - synthesizer_ar.py - value 0.0399 achieved after 3.75 seconds
2025-01-21 15:52:26,084 - synthesizer_ar.py - value 0.0406 achieved after 4.5 seconds
2025-01-21 15:52:26,874 - synthesizer_ar.py - value 0.0452 achieved after 5.29 seconds
> progress 0.267%, elapsed 3 s, estimated 1125 s, iters = {MDP: 91}, opt = 0.0452
2025-01-21 15:52:28,231 - synthesizer_ar.py - value 0.0453 achieved after 6.65 seconds
> progress 0.802%, elapsed 6 s, estimated 754 s, iters = {MDP: 172}, opt = 0.0453
> progress 1.235%, elapsed 9 s, estimated 734 s, iters = {MDP: 254}, opt = 0.0453
> progress 3.483%, elapsed 12 s, estimated 346 s, iters = {MDP: 341}, opt = 0.0453
> progress 6.083%, elapsed 15 s, estimated 247 s, iters = {MDP: 426}, opt = 0.0453
> progress 12.928%, elapsed 18 s, estimated 140 s, iters = {MDP: 511}, opt = 0.0453
> progress 16.31%, elapsed 21 s, estimated 129 s, iters = {MDP: 597}, opt = 0.0453
> progress 23.246%, elapsed 24 s, estimated 104 s, iters = {MDP: 673}, opt = 0.0453
> progress 30.206%, elapsed 27 s, estimated 90 s, iters = {MDP: 762}, opt = 0.0453
> progress 40.138%, elapsed 30 s, estimated 75 s, iters = {MDP: 854}, opt = 0.0453
> progress 42.373%, elapsed 33 s, estimated 78 s, iters = {MDP: 936}, opt = 0.0453
> progress 45.22%, elapsed 36 s, estimated 80 s, iters = {MDP: 1016}, opt = 0.0453
> progress 51.871%, elapsed 39 s, estimated 75 s, iters = {MDP: 1090}, opt = 0.0453
> progress 55.389%, elapsed 42 s, estimated 76 s, iters = {MDP: 1172}, opt = 0.0453
> progress 61.764%, elapsed 45 s, estimated 73 s, iters = {MDP: 1244}, opt = 0.0453
> progress 72.192%, elapsed 48 s, estimated 67 s, iters = {MDP: 1314}, opt = 0.0453
> progress 82.352%, elapsed 51 s, estimated 62 s, iters = {MDP: 1383}, opt = 0.0453
> progress 100.0%, elapsed 54 s, estimated 54 s, iters = {MDP: 1448}, opt = 0.0453
> progress 106.071%, elapsed 57 s, estimated 54 s, iters = {MDP: 1540}, opt = 0.0453
> progress 107.628%, elapsed 60 s, estimated 56 s, iters = {MDP: 1625}, opt = 0.0453
> progress 111.497%, elapsed 63 s, estimated 57 s, iters = {MDP: 1709}, opt = 0.0453
> progress 118.194%, elapsed 66 s, estimated 56 s, iters = {MDP: 1782}, opt = 0.0453
> progress 118.968%, elapsed 69 s, estimated 58 s, iters = {MDP: 1887}, opt = 0.0453
> progress 121.119%, elapsed 72 s, estimated 59 s, iters = {MDP: 1979}, opt = 0.0453
> progress 127.807%, elapsed 75 s, estimated 59 s, iters = {MDP: 2059}, opt = 0.0453
> progress 128.682%, elapsed 78 s, estimated 61 s, iters = {MDP: 2140}, opt = 0.0453
> progress 132.159%, elapsed 81 s, estimated 61 s, iters = {MDP: 2214}, opt = 0.0453
> progress 137.039%, elapsed 84 s, estimated 61 s, iters = {MDP: 2290}, opt = 0.0453
> progress 140.234%, elapsed 87 s, estimated 62 s, iters = {MDP: 2378}, opt = 0.0453
> progress 143.85%, elapsed 90 s, estimated 63 s, iters = {MDP: 2461}, opt = 0.0453
> progress 147.593%, elapsed 93 s, estimated 63 s, iters = {MDP: 2545}, opt = 0.0453
> progress 150.876%, elapsed 96 s, estimated 64 s, iters = {MDP: 2625}, opt = 0.0453
> progress 163.101%, elapsed 99 s, estimated 61 s, iters = {MDP: 2702}, opt = 0.0453
> progress 176.179%, elapsed 102 s, estimated 58 s, iters = {MDP: 2786}, opt = 0.0453
> progress 185.561%, elapsed 105 s, estimated 57 s, iters = {MDP: 2848}, opt = 0.0453
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 107.81 s
number of holes: 14, family size: 1e11, quotient: 3127 states / 106318 actions
explored: 200 %
MDP stats: avg MDP size: 3055, iterations: 2884

optimum: 0.045338
--------------------
2025-01-21 15:54:11,684 - decision_tree.py - families considered: 2884
2025-01-21 15:54:11,684 - decision_tree.py - families skipped by construction: 0
2025-01-21 15:54:11,684 - decision_tree.py - families with schedulers preserved: 119
2025-01-21 15:54:11,684 - decision_tree.py - families model checked: 2765
2025-01-21 15:54:11,684 - decision_tree.py - harmonizations attempted: 905
2025-01-21 15:54:11,684 - decision_tree.py - harmonizations succeeded: 6

2025-01-21 15:54:11,684 - decision_tree.py - printing synthesized assignment below:
2025-01-21 15:54:11,684 - decision_tree.py - V_0=c1, backoff1_0=0, backoff2_0=0, bc1_0=0, bc2_0=0, c1_0=0, c2_0=0, col_0=0, s1_0=1, s2_0=1, x1_0=0, x2_0=0, A_1=time, A_2=station2_cmd_54
2025-01-21 15:54:11,691 - decision_tree.py - double-checking specification satisfiability:  : 0.04533787523644744
2025-01-21 15:54:11,692 - decision_tree.py - the optimal scheduler has value: 0.10827098374814313
2025-01-21 15:54:11,692 - decision_tree.py - the random scheduler has value: 0.02730039610596835
2025-01-21 15:54:11,692 - decision_tree.py - synthesized tree of depth 1 with 1 decision nodes
2025-01-21 15:54:11,692 - decision_tree.py - the synthesized tree has value 0.04533787523644744
2025-01-21 15:54:11,692 - decision_tree.py - the synthesized tree has relative value: 0.2227658172642925
2025-01-21 15:54:11,692 - decision_tree.py - printing the synthesized tree below:
if c1<=0:
  time
else:
  station2_cmd_54

2025-01-21 15:54:11,693 - decision_tree.py - exported decision tree to logs/01-21-all/1/qcomp-wlan-1-2/tree.dot
2025-01-21 15:54:11,729 - decision_tree.py - exported decision tree visualization to logs/01-21-all/1/qcomp-wlan-1-2/tree.png
2025-01-21 15:54:11,729 - decision_tree.py - synthesis finished after 110.15 seconds

ColoringSmt = 0.302 s (0.3 %)
ColoringSmt:: create choice colors = 0.102 s (0.1 %)
ColoringSmt:: create harmonizing variants = 0.197 s (0.2 %)
areChoicesConsistent = 50.18 s (45.6 %)
areChoicesConsistent::1 is scheduler consistent? = 36.036 s (32.7 %)
areChoicesConsistent::2 better unsat core = 10.51 s (9.5 %)
areChoicesConsistent::3 unsat core analysis = 1.467 s (1.3 %)
check = 35.126 s (31.9 %)
loadUnsatCore = 0.012 s (0.0 %)
selectCompatibleChoices = 18.891 s (17.2 %)
selectCompatibleChoices::1 is family sat = 7.815 s (7.1 %)
selectCompatibleChoices::2 state exploration = 11.072 s (10.1 %)
