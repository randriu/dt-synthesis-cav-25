2025-01-21 15:51:57,662 - cli.py - This is Paynt version 0.1.0.
2025-01-21 15:51:57,662 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/qcomp/firewire-3/model-random-enabled.drn ...
2025-01-21 15:51:57,662 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 15:51:57,719 - sketch.py - assuming sketch in DRN format...
2025-01-21 15:51:57,784 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/qcomp/firewire-3/discounted.props ...
2025-01-21 15:51:57,785 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 15:51:57,799 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/qcomp/firewire-3/state-valuations.json, adding to the model...
2025-01-21 15:51:57,805 - sketch.py - sketch parsing OK
2025-01-21 15:51:57,851 - sketch.py - constructed explicit quotient having 4094 states and 57316 choices
2025-01-21 15:51:57,851 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 15:51:57,861 - mdp.py - MDP has 4093/4094 relevant states
2025-01-21 15:51:58,009 - mdp.py - MDP has 14 actions
2025-01-21 15:51:58,034 - mdp.py - found the following 10 variables: ['s1:[0..8]', 's2:[0..8]', 'w12:[0..8]', 'w21:[0..8]', 'x1:[0..167]', 'x2:[0..167]', 'y1:[0..4]', 'y2:[0..3]', 'z1:[0..4]', 'z2:[0..3]']
2025-01-21 15:51:58,042 - decision_tree.py - the optimal scheduler has value: -70.04494709788844
2025-01-21 15:51:58,045 - decision_tree.py - the random scheduler has value: -76.33806043806698

2025-01-21 15:51:58,046 - mdp.py - building tree of depth 0
2025-01-21 15:51:58,102 - statistic.py - synthesis initiated, design space: 14
2025-01-21 15:51:58,126 - synthesizer_ar.py - value -76.3198 achieved after 0.46 seconds
2025-01-21 15:51:58,189 - synthesizer_ar.py - value -76.258 achieved after 0.53 seconds
2025-01-21 15:51:58,256 - synthesizer_ar.py - value -73.3698 achieved after 0.59 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.21 s
number of holes: 1, family size: 14, quotient: 4094 states / 57316 actions
explored: 100 %
MDP stats: avg MDP size: 3675, iterations: 19

optimum: -73.36979
--------------------
2025-01-21 15:51:58,308 - decision_tree.py - families considered: 19
2025-01-21 15:51:58,308 - decision_tree.py - families skipped by construction: 0
2025-01-21 15:51:58,308 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 15:51:58,308 - decision_tree.py - families model checked: 19
2025-01-21 15:51:58,308 - decision_tree.py - harmonizations attempted: 6
2025-01-21 15:51:58,308 - decision_tree.py - harmonizations succeeded: 3

2025-01-21 15:51:58,308 - decision_tree.py - printing synthesized assignment below:
2025-01-21 15:51:58,308 - decision_tree.py - A_0=rec_req12
2025-01-21 15:51:58,311 - decision_tree.py - double-checking specification satisfiability:  : -73.36978975955904

2025-01-21 15:51:58,311 - mdp.py - building tree of depth 1
2025-01-21 15:51:58,607 - statistic.py - synthesis initiated, design space: 1e12
2025-01-21 15:52:00,002 - synthesizer_ar.py - value -73.3685 achieved after 2.34 seconds
> progress 0.706%, elapsed 3 s, estimated 428 s, iters = {MDP: 68}, opt = -73.3685
2025-01-21 15:52:03,220 - synthesizer_ar.py - value -73.362 achieved after 5.56 seconds
> progress 1.867%, elapsed 6 s, estimated 323 s, iters = {MDP: 144}, opt = -73.362
2025-01-21 15:52:07,417 - synthesizer_ar.py - value -73.292 achieved after 9.76 seconds
> progress 4.279%, elapsed 9 s, estimated 214 s, iters = {MDP: 211}, opt = -73.292
> progress 5.714%, elapsed 12 s, estimated 213 s, iters = {MDP: 292}, opt = -73.292
2025-01-21 15:52:11,620 - synthesizer_ar.py - value -73.2572 achieved after 13.96 seconds
> progress 6.994%, elapsed 15 s, estimated 228 s, iters = {MDP: 340}, opt = -73.2572
> progress 7.488%, elapsed 18 s, estimated 253 s, iters = {MDP: 372}, opt = -73.2572
2025-01-21 15:52:17,830 - synthesizer_ar.py - value -72.2551 achieved after 20.17 seconds
2025-01-21 15:52:18,208 - synthesizer_ar.py - value -71.449 achieved after 20.55 seconds
2025-01-21 15:52:18,768 - synthesizer_ar.py - value -70.5254 achieved after 21.11 seconds
> progress 10.714%, elapsed 22 s, estimated 205 s, iters = {MDP: 465}, opt = -70.5254
> progress 24.387%, elapsed 25 s, estimated 102 s, iters = {MDP: 590}, opt = -70.5254
> progress 31.454%, elapsed 28 s, estimated 89 s, iters = {MDP: 690}, opt = -70.5254
> progress 33.061%, elapsed 31 s, estimated 94 s, iters = {MDP: 791}, opt = -70.5254
> progress 35.306%, elapsed 34 s, estimated 96 s, iters = {MDP: 878}, opt = -70.5254
> progress 42.193%, elapsed 37 s, estimated 88 s, iters = {MDP: 979}, opt = -70.5254
> progress 49.923%, elapsed 40 s, estimated 80 s, iters = {MDP: 1082}, opt = -70.5254
> progress 57.345%, elapsed 43 s, estimated 75 s, iters = {MDP: 1188}, opt = -70.5254
> progress 60.596%, elapsed 46 s, estimated 76 s, iters = {MDP: 1279}, opt = -70.5254
> progress 64.251%, elapsed 49 s, estimated 76 s, iters = {MDP: 1355}, opt = -70.5254
> progress 66.301%, elapsed 52 s, estimated 79 s, iters = {MDP: 1451}, opt = -70.5254
> progress 70.025%, elapsed 55 s, estimated 79 s, iters = {MDP: 1548}, opt = -70.5254
> progress 83.265%, elapsed 58 s, estimated 70 s, iters = {MDP: 1659}, opt = -70.5254
> progress 100.706%, elapsed 61 s, estimated 61 s, iters = {MDP: 1766}, opt = -70.5254
> progress 103.672%, elapsed 64 s, estimated 62 s, iters = {MDP: 1856}, opt = -70.5254
> progress 109.892%, elapsed 67 s, estimated 61 s, iters = {MDP: 1934}, opt = -70.5254
> progress 110.102%, elapsed 70 s, estimated 64 s, iters = {MDP: 2033}, opt = -70.5254
> progress 116.938%, elapsed 73 s, estimated 63 s, iters = {MDP: 2155}, opt = -70.5254
> progress 130.0%, elapsed 76 s, estimated 59 s, iters = {MDP: 2263}, opt = -70.5254
> progress 132.971%, elapsed 79 s, estimated 59 s, iters = {MDP: 2366}, opt = -70.5254
> progress 136.262%, elapsed 82 s, estimated 60 s, iters = {MDP: 2451}, opt = -70.5254
> progress 138.265%, elapsed 85 s, estimated 62 s, iters = {MDP: 2560}, opt = -70.5254
> progress 142.704%, elapsed 88 s, estimated 62 s, iters = {MDP: 2675}, opt = -70.5254
> progress 146.619%, elapsed 92 s, estimated 62 s, iters = {MDP: 2778}, opt = -70.5254
> progress 152.577%, elapsed 95 s, estimated 62 s, iters = {MDP: 2889}, opt = -70.5254
> progress 157.139%, elapsed 98 s, estimated 62 s, iters = {MDP: 2995}, opt = -70.5254
> progress 159.136%, elapsed 101 s, estimated 63 s, iters = {MDP: 3085}, opt = -70.5254
> progress 163.171%, elapsed 104 s, estimated 63 s, iters = {MDP: 3157}, opt = -70.5254
> progress 164.783%, elapsed 107 s, estimated 65 s, iters = {MDP: 3240}, opt = -70.5254
> progress 166.658%, elapsed 110 s, estimated 66 s, iters = {MDP: 3337}, opt = -70.5254
> progress 170.663%, elapsed 113 s, estimated 66 s, iters = {MDP: 3420}, opt = -70.5254
> progress 184.336%, elapsed 116 s, estimated 63 s, iters = {MDP: 3523}, opt = -70.5254
> progress 193.673%, elapsed 119 s, estimated 61 s, iters = {MDP: 3623}, opt = -70.5254
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 120.74 s
number of holes: 13, family size: 1e12, quotient: 4094 states / 57316 actions
explored: 200 %
MDP stats: avg MDP size: 3732, iterations: 3667

optimum: -70.525419
--------------------
2025-01-21 15:53:59,347 - decision_tree.py - families considered: 3667
2025-01-21 15:53:59,347 - decision_tree.py - families skipped by construction: 0
2025-01-21 15:53:59,347 - decision_tree.py - families with schedulers preserved: 196
2025-01-21 15:53:59,347 - decision_tree.py - families model checked: 3471
2025-01-21 15:53:59,347 - decision_tree.py - harmonizations attempted: 1107
2025-01-21 15:53:59,347 - decision_tree.py - harmonizations succeeded: 7

2025-01-21 15:53:59,347 - decision_tree.py - printing synthesized assignment below:
2025-01-21 15:53:59,347 - decision_tree.py - V_0=x2, s1_0=0, s2_0=0, w12_0=0, w21_0=0, x1_0=0, x2_0=75, y1_0=0, y2_0=0, z1_0=0, z2_0=0, A_1=rec_req21, A_2=snd_req21
2025-01-21 15:53:59,349 - decision_tree.py - double-checking specification satisfiability:  : -70.52541927460231
2025-01-21 15:53:59,349 - decision_tree.py - the optimal scheduler has value: -70.04494709788844
2025-01-21 15:53:59,349 - decision_tree.py - the random scheduler has value: -76.33806043806698
2025-01-21 15:53:59,350 - decision_tree.py - synthesized tree of depth 1 with 1 decision nodes
2025-01-21 15:53:59,350 - decision_tree.py - the synthesized tree has value -70.52541927460231
2025-01-21 15:53:59,350 - decision_tree.py - the synthesized tree has relative value: 0.9236511165870336
2025-01-21 15:53:59,350 - decision_tree.py - printing the synthesized tree below:
if x2<=75:
  rec_req21
else:
  snd_req21

2025-01-21 15:53:59,351 - decision_tree.py - exported decision tree to logs/01-21-all/1/qcomp-firewire-3/tree.dot
2025-01-21 15:53:59,386 - decision_tree.py - exported decision tree visualization to logs/01-21-all/1/qcomp-firewire-3/tree.png
2025-01-21 15:53:59,386 - decision_tree.py - synthesis finished after 121.72 seconds

ColoringSmt = 0.27 s (0.2 %)
ColoringSmt:: create choice colors = 0.079 s (0.1 %)
ColoringSmt:: create harmonizing variants = 0.187 s (0.2 %)
areChoicesConsistent = 83.284 s (68.4 %)
areChoicesConsistent::1 is scheduler consistent? = 21.86 s (18.0 %)
areChoicesConsistent::2 better unsat core = 58.684 s (48.2 %)
areChoicesConsistent::3 unsat core analysis = 1.579 s (1.3 %)
check = 65.962 s (54.2 %)
loadUnsatCore = 0.012 s (0.0 %)
selectCompatibleChoices = 14.61 s (12.0 %)
selectCompatibleChoices::1 is family sat = 6.368 s (5.2 %)
selectCompatibleChoices::2 state exploration = 8.237 s (6.8 %)
