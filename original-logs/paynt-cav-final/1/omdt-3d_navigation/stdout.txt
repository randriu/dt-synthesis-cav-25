2025-01-21 15:51:52,434 - cli.py - This is Paynt version 0.1.0.
2025-01-21 15:51:52,434 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/omdt/3d_navigation/model-random.drn ...
2025-01-21 15:51:52,434 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 15:51:52,436 - sketch.py - assuming sketch in DRN format...
2025-01-21 15:51:52,438 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/omdt/3d_navigation/discounted.props ...
2025-01-21 15:51:52,438 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 15:51:52,438 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/omdt/3d_navigation/state-valuations.json, adding to the model...
2025-01-21 15:51:52,438 - sketch.py - sketch parsing OK
2025-01-21 15:51:52,438 - sketch.py - constructed explicit quotient having 125 states and 875 choices
2025-01-21 15:51:52,438 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 15:51:52,439 - mdp.py - MDP has 125/125 relevant states
2025-01-21 15:51:52,440 - mdp.py - MDP has 7 actions
2025-01-21 15:51:52,440 - mdp.py - found the following 3 variables: ['x:[0..4]', 'y:[0..4]', 'z:[0..4]']
2025-01-21 15:51:52,444 - decision_tree.py - the optimal scheduler has value: 0.3518477922915202
2025-01-21 15:51:52,445 - decision_tree.py - the random scheduler has value: 1.1945613532024873e-06

2025-01-21 15:51:52,445 - mdp.py - building tree of depth 0
2025-01-21 15:51:52,449 - statistic.py - synthesis initiated, design space: 7
2025-01-21 15:51:52,453 - synthesizer_ar.py - value 0.0 achieved after 0.02 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.01 s
number of holes: 1, family size: 7, quotient: 125 states / 875 actions
explored: 100 %
MDP stats: avg MDP size: 65, iterations: 4

optimum: 0.0
--------------------
2025-01-21 15:51:52,455 - decision_tree.py - families considered: 4
2025-01-21 15:51:52,455 - decision_tree.py - families skipped by construction: 0
2025-01-21 15:51:52,455 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 15:51:52,455 - decision_tree.py - families model checked: 4
2025-01-21 15:51:52,455 - decision_tree.py - harmonizations attempted: 1
2025-01-21 15:51:52,455 - decision_tree.py - harmonizations succeeded: 1

2025-01-21 15:51:52,455 - decision_tree.py - printing synthesized assignment below:
2025-01-21 15:51:52,455 - decision_tree.py - A_0=(forward)
2025-01-21 15:51:52,455 - decision_tree.py - double-checking specification satisfiability:  : 0.0

2025-01-21 15:51:52,455 - mdp.py - building tree of depth 1
2025-01-21 15:51:52,464 - statistic.py - synthesis initiated, design space: 9408
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.28 s
number of holes: 6, family size: 9408, quotient: 125 states / 875 actions
explored: 200 %
MDP stats: avg MDP size: 87, iterations: 180

optimum: 0.0
--------------------
2025-01-21 15:51:52,743 - decision_tree.py - families considered: 180
2025-01-21 15:51:52,743 - decision_tree.py - families skipped by construction: 0
2025-01-21 15:51:52,743 - decision_tree.py - families with schedulers preserved: 20
2025-01-21 15:51:52,743 - decision_tree.py - families model checked: 160
2025-01-21 15:51:52,743 - decision_tree.py - harmonizations attempted: 44
2025-01-21 15:51:52,743 - decision_tree.py - harmonizations succeeded: 0

2025-01-21 15:51:52,743 - decision_tree.py - the optimal scheduler has value: 0.3518477922915202
2025-01-21 15:51:52,743 - decision_tree.py - the random scheduler has value: 1.1945613532024873e-06
2025-01-21 15:51:52,743 - decision_tree.py - synthesized tree of depth 0 with 0 decision nodes
2025-01-21 15:51:52,744 - decision_tree.py - the synthesized tree has value 0.0
2025-01-21 15:51:52,744 - decision_tree.py - the synthesized tree has relative value: -3.3951198076344703e-06
2025-01-21 15:51:52,744 - decision_tree.py - printing the synthesized tree below:
(forward)

2025-01-21 15:51:52,744 - decision_tree.py - exported decision tree to logs/01-21-all/1/omdt-3d_navigation/tree.dot
2025-01-21 15:51:52,778 - decision_tree.py - exported decision tree visualization to logs/01-21-all/1/omdt-3d_navigation/tree.png
2025-01-21 15:51:52,778 - decision_tree.py - synthesis finished after 0.34 seconds

ColoringSmt = 0.003 s (0.9 %)
ColoringSmt:: create choice colors = 0.001 s (0.3 %)
ColoringSmt:: create harmonizing variants = 0.002 s (0.6 %)
areChoicesConsistent = 0.121 s (35.6 %)
areChoicesConsistent::1 is scheduler consistent? = 0.046 s (13.5 %)
areChoicesConsistent::2 better unsat core = 0.046 s (13.5 %)
areChoicesConsistent::3 unsat core analysis = 0.026 s (7.6 %)
check = 0.108 s (31.8 %)
loadUnsatCore = 0.0 s (0.0 %)
selectCompatibleChoices = 0.057 s (16.8 %)
selectCompatibleChoices::1 is family sat = 0.052 s (15.3 %)
selectCompatibleChoices::2 state exploration = 0.004 s (1.2 %)
