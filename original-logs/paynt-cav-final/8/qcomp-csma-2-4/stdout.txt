2025-01-21 20:52:41,864 - cli.py - This is Paynt version 0.1.0.
2025-01-21 20:52:41,864 - sketch.py - loading sketch from /home/imacak/disk2/synthesis/models/dts/qcomp/csma-2-4/model-random-enabled.drn ...
2025-01-21 20:52:41,864 - sketch.py - assuming sketch in PRISM format...
ERROR (SpiritErrorHandler.h:26): Parsing error at 3:1:  expecting <model type>, here:
	@type: MDP
	^

2025-01-21 20:52:41,989 - sketch.py - assuming sketch in DRN format...
2025-01-21 20:52:42,695 - prism_parser.py - loading properties from /home/imacak/disk2/synthesis/models/dts/qcomp/csma-2-4/discounted.props ...
2025-01-21 20:52:42,696 - prism_parser.py - found the following specification: optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 20:52:42,720 - sketch.py - found state valuations in /home/imacak/disk2/synthesis/models/dts/qcomp/csma-2-4/state-valuations.json, adding to the model...
2025-01-21 20:52:42,733 - sketch.py - sketch parsing OK
2025-01-21 20:52:42,885 - sketch.py - constructed explicit quotient having 7959 states and 135303 choices
2025-01-21 20:52:42,885 - sketch.py - found the following specification optimality: R{"reward"}max=? [Cdiscount=99/100] 
2025-01-21 20:52:42,904 - mdp.py - MDP has 7958/7959 relevant states
2025-01-21 20:52:43,401 - mdp.py - MDP has 17 actions
2025-01-21 20:52:43,453 - mdp.py - found the following 11 variables: ['b:[0..15]', 'bc1:[0..15]', 'bc2:[0..15]', 'cd1:[0..4]', 'cd2:[0..4]', 's1:[0..4]', 's2:[0..4]', 'x1:[0..30]', 'x2:[0..30]', 'y1:[0..2]', 'y2:[0..1]']
2025-01-21 20:52:43,473 - decision_tree.py - the optimal scheduler has value: 0.39191032998543884
2025-01-21 20:52:43,481 - decision_tree.py - the random scheduler has value: 0.3851938934713688

2025-01-21 20:52:43,481 - mdp.py - building tree of depth 0
2025-01-21 20:52:43,607 - statistic.py - synthesis initiated, design space: 17
2025-01-21 20:52:43,704 - synthesizer_ar.py - value 0.3852 achieved after 1.84 seconds
2025-01-21 20:52:43,831 - synthesizer_ar.py - value 0.3883 achieved after 1.97 seconds
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 0.58 s
number of holes: 1, family size: 17, quotient: 7959 states / 135303 actions
explored: 100 %
MDP stats: avg MDP size: 7949, iterations: 16

optimum: 0.388281
--------------------
2025-01-21 20:52:44,189 - decision_tree.py - families considered: 16
2025-01-21 20:52:44,189 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:52:44,189 - decision_tree.py - families with schedulers preserved: 0
2025-01-21 20:52:44,189 - decision_tree.py - families model checked: 16
2025-01-21 20:52:44,189 - decision_tree.py - harmonizations attempted: 5
2025-01-21 20:52:44,189 - decision_tree.py - harmonizations succeeded: 2

2025-01-21 20:52:44,189 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:52:44,189 - decision_tree.py - A_0=cd
2025-01-21 20:52:44,199 - decision_tree.py - double-checking specification satisfiability:  : 0.38828119880815554

2025-01-21 20:52:44,199 - mdp.py - building tree of depth 1
2025-01-21 20:52:44,852 - statistic.py - synthesis initiated, design space: 1e12
> progress 1.093%, elapsed 3 s, estimated 282 s, iters = {MDP: 26}, opt = 0.3883
2025-01-21 20:52:48,439 - synthesizer_ar.py - value 0.3901 achieved after 6.57 seconds
> progress 10.388%, elapsed 6 s, estimated 59 s, iters = {MDP: 54}, opt = 0.3901
> progress 18.181%, elapsed 9 s, estimated 50 s, iters = {MDP: 91}, opt = 0.3901
> progress 28.319%, elapsed 12 s, estimated 43 s, iters = {MDP: 121}, opt = 0.3901
> progress 44.039%, elapsed 15 s, estimated 34 s, iters = {MDP: 151}, opt = 0.3901
> progress 47.025%, elapsed 18 s, estimated 39 s, iters = {MDP: 187}, opt = 0.3901
> progress 100.0%, elapsed 21 s, estimated 21 s, iters = {MDP: 232}, opt = 0.3901
> progress 123.529%, elapsed 24 s, estimated 19 s, iters = {MDP: 261}, opt = 0.3901
> progress 143.85%, elapsed 27 s, estimated 19 s, iters = {MDP: 296}, opt = 0.3901
> progress 144.479%, elapsed 30 s, estimated 21 s, iters = {MDP: 323}, opt = 0.3901
> progress 144.982%, elapsed 34 s, estimated 23 s, iters = {MDP: 362}, opt = 0.3901
> progress 147.058%, elapsed 37 s, estimated 25 s, iters = {MDP: 395}, opt = 0.3901
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 38.54 s
number of holes: 14, family size: 1e12, quotient: 7959 states / 135303 actions
explored: 200 %
MDP stats: avg MDP size: 7950, iterations: 413

optimum: 0.390096
--------------------
2025-01-21 20:53:23,387 - decision_tree.py - families considered: 413
2025-01-21 20:53:23,388 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:53:23,388 - decision_tree.py - families with schedulers preserved: 39
2025-01-21 20:53:23,388 - decision_tree.py - families model checked: 374
2025-01-21 20:53:23,388 - decision_tree.py - harmonizations attempted: 107
2025-01-21 20:53:23,388 - decision_tree.py - harmonizations succeeded: 1

2025-01-21 20:53:23,388 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:53:23,388 - decision_tree.py - V_0=s1, b_0=0, bc1_0=0, bc2_0=0, cd1_0=0, cd2_0=0, s1_0=2, s2_0=0, x1_0=0, x2_0=0, y1_0=0, y2_0=0, A_1=cd, A_2=end2
2025-01-21 20:53:23,400 - decision_tree.py - double-checking specification satisfiability:  : 0.39009576449994304

2025-01-21 20:53:23,401 - mdp.py - building tree of depth 2
2025-01-21 20:53:25,249 - statistic.py - synthesis initiated, design space: 1e35
> progress 0.133%, elapsed 3 s, estimated 2339 s, iters = {MDP: 15}, opt = 0.3901
> progress 0.267%, elapsed 6 s, estimated 2438 s, iters = {MDP: 30}, opt = 0.3901
> progress 0.288%, elapsed 9 s, estimated 3388 s, iters = {MDP: 44}, opt = 0.3901
> progress 0.292%, elapsed 13 s, estimated 4502 s, iters = {MDP: 61}, opt = 0.3901
> progress 0.292%, elapsed 16 s, estimated 5596 s, iters = {MDP: 70}, opt = 0.3901
> progress 0.292%, elapsed 19 s, estimated 6700 s, iters = {MDP: 72}, opt = 0.3901
> progress 0.292%, elapsed 24 s, estimated 8546 s (2 hours), iters = {MDP: 74}, opt = 0.3901
> progress 0.292%, elapsed 28 s, estimated 9611 s (2 hours), iters = {MDP: 75}, opt = 0.3901
2025-01-21 20:53:57,443 - synthesizer_ar.py - value 0.3919 achieved after 75.58 seconds
> progress 0.292%, elapsed 32 s, estimated 11027 s (3 hours), iters = {MDP: 76}, opt = 0.3919
> progress 0.293%, elapsed 35 s, estimated 12057 s (3 hours), iters = {MDP: 112}, opt = 0.3919
> progress 0.295%, elapsed 38 s, estimated 13108 s (3 hours), iters = {MDP: 135}, opt = 0.3919
--------------------
Synthesis summary:
optimality objective: R{"reward"}max=? [Cdiscount=99/100] 

method: AR (decision tree), synthesis time: 39.6 s
number of holes: 40, family size: 1e35, quotient: 7959 states / 135303 actions
explored: 102 %
MDP stats: avg MDP size: 7933, iterations: 147

optimum: 0.39191
--------------------
2025-01-21 20:54:04,851 - decision_tree.py - families considered: 147
2025-01-21 20:54:04,851 - decision_tree.py - families skipped by construction: 0
2025-01-21 20:54:04,851 - decision_tree.py - families with schedulers preserved: 25
2025-01-21 20:54:04,851 - decision_tree.py - families model checked: 122
2025-01-21 20:54:04,851 - decision_tree.py - harmonizations attempted: 30
2025-01-21 20:54:04,851 - decision_tree.py - harmonizations succeeded: 1

2025-01-21 20:54:04,851 - decision_tree.py - printing synthesized assignment below:
2025-01-21 20:54:04,851 - decision_tree.py - V_0=s1, b_0=0, bc1_0=0, bc2_0=0, cd1_0=0, cd2_0=0, s1_0=2, s2_0=0, x1_0=0, x2_0=0, y1_0=0, y2_0=0, V_1=s2, b_1=0, bc1_1=0, bc2_1=0, cd1_1=0, cd2_1=0, s1_1=0, s2_1=2, x1_1=0, x2_1=0, y1_1=0, y2_1=0, A_2=cd, A_3=end1, V_4=x2, b_4=0, bc1_4=0, bc2_4=0, cd1_4=3, cd2_4=0, s1_4=3, s2_4=0, x1_4=1, x2_4=23, y1_4=0, y2_4=0, A_5=time, A_6=end2
2025-01-21 20:54:04,866 - decision_tree.py - double-checking specification satisfiability:  : 0.39191032998543884
2025-01-21 20:54:04,866 - decision_tree.py - the optimal scheduler has value: 0.39191032998543884
2025-01-21 20:54:04,866 - decision_tree.py - the random scheduler has value: 0.3851938934713688
2025-01-21 20:54:04,870 - decision_tree.py - synthesized tree of depth 2 with 3 decision nodes
2025-01-21 20:54:04,870 - decision_tree.py - the synthesized tree has value 0.39191032998543884
2025-01-21 20:54:04,870 - decision_tree.py - the synthesized tree has relative value: 1.0
2025-01-21 20:54:04,870 - decision_tree.py - printing the synthesized tree below:
if s1<=2:
  if s2<=2:
    cd
  else:
    end1
else:
  if x2<=23:
    time
  else:
    end2

2025-01-21 20:54:04,871 - decision_tree.py - exported decision tree to logs/01-21-all/8/qcomp-csma-2-4/tree.dot
2025-01-21 20:54:04,911 - decision_tree.py - exported decision tree visualization to logs/01-21-all/8/qcomp-csma-2-4/tree.png
2025-01-21 20:54:04,911 - decision_tree.py - synthesis finished after 83.05 seconds

ColoringSmt = 1.72 s (2.1 %)
ColoringSmt:: create choice colors = 0.475 s (0.6 %)
ColoringSmt:: create harmonizing variants = 1.239 s (1.5 %)
areChoicesConsistent = 32.896 s (39.6 %)
areChoicesConsistent::1 is scheduler consistent? = 16.569 s (20.0 %)
areChoicesConsistent::2 better unsat core = 15.335 s (18.5 %)
areChoicesConsistent::3 unsat core analysis = 0.151 s (0.2 %)
check = 26.581 s (32.0 %)
loadUnsatCore = 0.0 s (0.0 %)
selectCompatibleChoices = 2.131 s (2.6 %)
selectCompatibleChoices::1 is family sat = 1.018 s (1.2 %)
selectCompatibleChoices::2 state exploration = 1.112 s (1.3 %)
